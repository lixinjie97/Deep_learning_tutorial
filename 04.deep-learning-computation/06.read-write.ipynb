{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637fd2da-44c9-49fc-95b0-37d456bbc6ec",
   "metadata": {},
   "source": [
    "# 读写文件\n",
    "\n",
    "到目前为止，我们讨论了如何处理数据，\n",
    "以及如何构建、训练和测试深度学习模型。\n",
    "然而，有时我们希望保存训练的模型，\n",
    "以备将来在各种环境中使用（比如在部署中进行预测）。\n",
    "此外，当运行一个耗时较长的训练过程时，\n",
    "最佳的做法是定期保存中间结果，\n",
    "以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。\n",
    "因此，现在是时候学习如何加载和存储权重向量和整个模型了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e47d1f-ba97-4b6f-bb59-82dc52dca87a",
   "metadata": {},
   "source": [
    "## (**加载和保存张量**)\n",
    "\n",
    "对于单个张量，我们可以直接调用`load`和`save`函数分别读写它们。\n",
    "这两个函数都要求我们提供一个名称，`save`要求将要保存的变量作为输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ffaf1a-61b7-4199-9eaa-bb0e1d975799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3b5ef-d6f7-4f14-9216-559ddcb8e37e",
   "metadata": {},
   "source": [
    "我们现在可以将存储在文件中的数据读回内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99896573-f66d-48e0-b67e-4bef1632630f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8805a0fc-2bd6-4cad-ad72-d8ae2d877318",
   "metadata": {},
   "source": [
    "我们可以[**存储一个张量列表，然后把它们读回内存。**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b9e0a6-2f77-4e91-b8fa-e43c32f54ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y], 'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf0794-056b-4a27-b0d7-a0d67d118b75",
   "metadata": {},
   "source": [
    "我们甚至可以(**写入或读取从字符串映射到张量的字典**)。\n",
    "当我们要读取或写入模型中的所有权重时，这很方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c5cb6b-4147-4f8a-97d6-e7fd1b5931c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c43104-2b6e-4bba-9cb7-2118e0d88206",
   "metadata": {},
   "source": [
    "## [**加载和保存模型参数**]\n",
    "\n",
    "保存单个权重向量（或其他张量）确实有用，\n",
    "但是如果我们想保存整个模型，并在以后加载它们，\n",
    "单独保存每个向量则会变得很麻烦。\n",
    "毕竟，我们可能有数百个参数散布在各处。\n",
    "因此，深度学习框架提供了内置函数来保存和加载整个网络。\n",
    "**需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。**\n",
    "例如，如果我们有一个3层多层感知机，我们需要单独指定架构。\n",
    "因为模型本身可以包含任意代码，所以模型本身难以序列化。\n",
    "因此，为了恢复模型，我们需要用代码生成架构，\n",
    "然后从磁盘加载参数。\n",
    "让我们从熟悉的多层感知机开始尝试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f26466-dc2b-43b5-a625-87cbc1d380c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4717,  0.7608, -0.2460, -0.5224,  1.8961, -0.3454, -0.0133,  1.5230,\n",
       "          -0.3957, -0.1714, -1.8560,  0.7084, -0.0031,  0.1693,  0.1832,  0.6183,\n",
       "          -0.5887,  1.9986,  0.7505, -0.1436],\n",
       "         [-0.1473,  0.1644,  0.2538,  0.7431,  0.4841,  0.0939, -0.5621,  0.0082,\n",
       "          -0.1713,  0.2585,  0.6824,  0.3604,  0.8227,  0.1294, -0.4082, -0.3461,\n",
       "           0.6684, -0.6188, -0.5184,  0.4627]]),\n",
       " tensor([[ 0.0556, -0.0790,  0.0728, -0.0750,  0.1486,  0.1396, -0.2337,  0.1133,\n",
       "           0.1514,  0.0022],\n",
       "         [-0.0183, -0.0565,  0.0204,  0.0016, -0.0048,  0.2369,  0.0323,  0.1494,\n",
       "           0.0461, -0.1177]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4603962-a4e0-4cf2-ad0f-beff9ad2956d",
   "metadata": {},
   "source": [
    "接下来，我们[**将模型的参数存储在一个叫做“mlp.params”的文件中。**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "607d1787-b4e8-4ea4-bac3-ea31f7bc3aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[ 0.1166,  0.1421,  0.0079,  ..., -0.2129, -0.0159, -0.2110],\n",
       "                      [-0.1750, -0.0147, -0.1130,  ...,  0.0023, -0.0808, -0.1055],\n",
       "                      [-0.1670, -0.1670,  0.1465,  ...,  0.1507,  0.0674,  0.0513],\n",
       "                      ...,\n",
       "                      [ 0.1201, -0.0734, -0.1010,  ..., -0.0786,  0.1808,  0.2135],\n",
       "                      [-0.1636,  0.0960, -0.0222,  ...,  0.1768,  0.1840,  0.1018],\n",
       "                      [ 0.0564,  0.1881,  0.0744,  ..., -0.1790,  0.0665, -0.1621]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([ 7.3997e-02, -7.7489e-02,  2.0512e-01,  1.0465e-01,  1.0354e-01,\n",
       "                      -9.7469e-02,  1.9908e-01,  6.9771e-02, -3.3769e-02,  9.9017e-02,\n",
       "                      -1.7160e-01,  1.7985e-01, -2.1898e-01,  5.4486e-02, -1.1885e-01,\n",
       "                      -2.1886e-01, -2.1454e-01, -1.0504e-02,  1.7328e-01,  2.3252e-02,\n",
       "                       1.1865e-01,  1.1366e-01, -2.1297e-01, -1.3888e-02, -2.0219e-01,\n",
       "                      -1.8852e-01, -1.3015e-01, -1.4577e-02,  7.3678e-03, -1.5946e-01,\n",
       "                       7.1097e-02, -1.7383e-01, -5.0449e-03, -2.1556e-01,  1.3077e-01,\n",
       "                      -2.1099e-01, -1.2741e-01, -1.4074e-01,  3.2665e-02, -9.6904e-02,\n",
       "                       2.3288e-02,  2.0080e-01,  3.7337e-02,  9.3953e-02, -6.3848e-02,\n",
       "                       7.1241e-02, -2.2358e-02, -3.4233e-02,  4.5167e-02, -1.7862e-01,\n",
       "                       1.4836e-01,  1.2847e-01,  3.3151e-02, -1.4747e-01, -2.1376e-01,\n",
       "                      -1.1009e-01,  2.1755e-02, -1.3960e-01, -1.7467e-01,  6.3087e-02,\n",
       "                       1.2775e-01,  2.0827e-01,  2.1060e-01,  2.0316e-01, -1.4874e-01,\n",
       "                       5.2628e-02, -1.6246e-01,  1.8193e-01,  1.2560e-01,  5.7843e-02,\n",
       "                      -1.1009e-01, -5.6957e-02,  5.9081e-02, -1.0688e-01, -1.6390e-01,\n",
       "                      -1.3847e-01, -1.8608e-01,  1.1889e-01, -6.4504e-02, -1.9002e-01,\n",
       "                      -5.1382e-02, -2.8179e-03, -1.0147e-01,  1.6187e-02, -4.5650e-02,\n",
       "                      -8.7213e-02,  9.9363e-02,  5.6140e-02,  1.0602e-01,  1.8335e-01,\n",
       "                       2.2145e-01,  1.8516e-02, -2.0384e-01, -1.1012e-02,  1.9630e-01,\n",
       "                      -2.2135e-01,  2.1398e-01,  1.5864e-01,  2.2438e-03,  7.6756e-02,\n",
       "                      -1.8495e-01, -1.1943e-01, -2.0391e-01, -3.2934e-03, -4.0708e-02,\n",
       "                      -7.3630e-02,  5.7703e-02, -6.6928e-02, -1.0893e-02,  1.7774e-01,\n",
       "                       1.4378e-04, -1.7467e-01,  7.8258e-02,  1.4252e-01, -3.9559e-02,\n",
       "                      -8.4286e-03, -7.3487e-02, -7.3665e-02, -7.9054e-02,  4.5124e-02,\n",
       "                      -2.2435e-02,  1.3564e-01,  2.9560e-03,  3.4991e-03,  1.7794e-01,\n",
       "                       2.0913e-01,  2.2318e-01,  9.3818e-02,  2.0809e-01, -2.0968e-01,\n",
       "                      -1.2225e-01, -1.7560e-01, -1.1724e-01, -1.4975e-01, -1.4238e-01,\n",
       "                       1.3187e-01, -2.6459e-02, -1.2624e-01,  2.0682e-01,  3.4706e-05,\n",
       "                      -1.8021e-01, -2.1670e-01,  2.1369e-02,  2.1656e-01,  6.5739e-02,\n",
       "                       6.9046e-02, -5.5980e-02,  1.7472e-02, -3.0791e-02,  5.0569e-02,\n",
       "                      -4.3613e-02, -1.0078e-01,  9.0065e-02,  1.2729e-01,  3.5860e-02,\n",
       "                       1.7862e-01,  8.2352e-02,  1.3209e-01, -2.0499e-02, -1.8952e-01,\n",
       "                       7.6782e-02,  2.0113e-02, -1.8023e-01, -2.9936e-03, -2.0169e-01,\n",
       "                       9.3751e-02,  1.7131e-02, -2.0238e-02,  2.1127e-01, -5.2690e-02,\n",
       "                       5.7470e-03, -7.2371e-02, -1.5052e-01, -2.2081e-01, -1.3287e-01,\n",
       "                      -1.6132e-01,  4.5506e-02,  2.0313e-01,  6.3580e-02, -1.1723e-01,\n",
       "                      -1.7999e-01,  1.7553e-03,  1.5651e-01,  1.5240e-01,  1.7947e-01,\n",
       "                      -2.0606e-02,  2.2567e-02, -1.6528e-01, -2.0784e-01,  1.3334e-01,\n",
       "                      -9.2509e-02, -9.8200e-02,  2.4571e-02, -2.0463e-01, -1.6545e-01,\n",
       "                       1.6561e-01, -4.8506e-02,  1.9564e-02,  1.3618e-01,  2.1163e-01,\n",
       "                      -8.1144e-02,  9.2322e-02,  1.6512e-02, -5.5346e-02,  7.5170e-02,\n",
       "                      -7.2882e-02, -1.3965e-01,  1.3372e-01,  1.6940e-02,  9.2012e-02,\n",
       "                       1.6965e-01, -1.8405e-01, -7.5664e-02, -2.0375e-01, -1.2042e-01,\n",
       "                       4.9968e-02, -2.1421e-01,  1.3146e-01,  1.1626e-01, -1.0392e-02,\n",
       "                       2.1276e-01,  6.7821e-03, -1.1962e-03, -5.3040e-02,  1.5451e-01,\n",
       "                       5.6490e-02, -4.2113e-03, -3.2668e-02,  9.5473e-02, -1.2137e-01,\n",
       "                      -1.1231e-01, -5.4240e-03, -3.7050e-02, -1.5914e-01, -1.9847e-01,\n",
       "                       1.7994e-01, -1.0641e-01, -1.7549e-01,  1.8244e-01, -1.3940e-01,\n",
       "                       1.4027e-02, -1.3294e-01,  3.4810e-02,  1.9182e-01, -2.0590e-01,\n",
       "                       1.6191e-02,  1.5968e-01,  8.5748e-02,  8.7852e-02, -5.9335e-02,\n",
       "                       8.7724e-02,  1.1534e-01, -7.4830e-02, -6.1367e-02, -1.5379e-01,\n",
       "                       1.6293e-01])),\n",
       "             ('output.weight',\n",
       "              tensor([[ 0.0200, -0.0054, -0.0169,  ..., -0.0398,  0.0086,  0.0312],\n",
       "                      [ 0.0468, -0.0366, -0.0566,  ..., -0.0362, -0.0258,  0.0397],\n",
       "                      [ 0.0369, -0.0501,  0.0051,  ...,  0.0252, -0.0227,  0.0319],\n",
       "                      ...,\n",
       "                      [-0.0418, -0.0022, -0.0159,  ...,  0.0460,  0.0327,  0.0310],\n",
       "                      [-0.0002,  0.0334,  0.0301,  ...,  0.0042, -0.0233,  0.0120],\n",
       "                      [-0.0177,  0.0605,  0.0061,  ..., -0.0539, -0.0480,  0.0306]])),\n",
       "             ('output.bias',\n",
       "              tensor([ 0.0030, -0.0382,  0.0580,  0.0412, -0.0520, -0.0015,  0.0029, -0.0397,\n",
       "                      -0.0196,  0.0069]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d991cc49-776e-454e-b7a9-f0edaa0b2767",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c1856-79c5-4709-a4bc-5e146ddab6fa",
   "metadata": {},
   "source": [
    "为了恢复模型，我们[**实例化了原始多层感知机模型的一个备份。**]\n",
    "这里我们不需要随机初始化模型参数，而是(**直接读取文件中存储的参数。**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c54a0b-0d42-4100-ab6e-fbbfefc3739a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b0a47-f972-4eb7-93e5-36b144547c22",
   "metadata": {},
   "source": [
    "由于两个实例具有相同的模型参数，在输入相同的`X`时，\n",
    "两个实例的计算结果应该相同。\n",
    "让我们来验证一下。\n",
    "\n",
    "注：eval评估模式下dropout会被关掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61a52d2-7a21-4083-9abb-a809fe98d6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3073da-21bc-49fa-adf7-d1afc3c6467f",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* `save`和`load`函数可用于张量对象的文件读写。\n",
    "* 我们可以通过参数字典保存和加载网络的全部参数。\n",
    "* 保存架构必须在代码中完成，而不是在参数中完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dee652-2412-4a6e-a466-c1c087a72b01",
   "metadata": {},
   "source": [
    "## 练习\n",
    "\n",
    "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？\n",
    "1. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？\n",
    "1. 如何同时保存网络架构和参数？需要对架构加上什么限制？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84930b8-b6e9-451f-b104-5f082a0539f0",
   "metadata": {},
   "source": [
    "### 练习一\n",
    "\n",
    "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5685a62-3b5c-456f-bf38-b2082a1b126d",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e0373-07ad-4fc4-965a-b0003b0d23d0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;1.便于模型恢复和微调：存储模型参数可以在训练中断后继续训练，或者在新的数据集上进行微调，而无需从头开始训练。\n",
    "\n",
    "&emsp;&emsp;2.节省存储空间：相比于保存完整的模型结构，保存模型参数通常占用更少的存储空间，这在处理大型模型或存储空间受限的情况下尤为重要。\n",
    "\n",
    "&emsp;&emsp;3.便于共享和复现：存储模型参数可以方便地共享和复现已经训练好的模型，其他人可以直接加载这些参数并使用它们进行预测或进一步训练。\n",
    "\n",
    "&emsp;&emsp;4.便于调试和分析：通过检查和分析模型参数，可以更容易地诊断模型中存在的问题，并对模型进行调整和优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f78314-35c9-4d2a-8155-278027dd6cf5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;下面将以一个简单的例子具体说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5be55-7b8d-41b9-8f3c-567bcefc19ae",
   "metadata": {},
   "source": [
    "&emsp;&emsp;1. 便于模型恢复和微调：假设我们有一个简单的神经网络模型，我们可以使用 PyTorch 保存和加载模型参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2594c3b6-0753-460d-9598-459c3c10974b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# 保存模型参数\n",
    "torch.save(model.state_dict(), 'model_parameters.pth')\n",
    "\n",
    "# 加载模型参数进行微调\n",
    "model.load_state_dict(torch.load('model_parameters.pth'))\n",
    "# 继续训练或进行微调..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc4463-ccbc-424a-83cb-fc61adb9be9c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;2. 节省存储空间：在上述示例中，通过使用`torch.save(model.state_dict(), 'model_parameters.pth')`只保存模型参数，而不是整个模型，可以节省存储空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb434a-03ee-45e5-9544-e4c58e4229d0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;3. 便于共享和复现：保存模型参数后，可以将 `model_parameters.pth` 文件与他人共享。他们可以使用以下代码加载参数并复现模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac392bf1-6b9d-4e4e-92d5-65bf16a38eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleModel()\n",
    "model.load_state_dict(torch.load('model_parameters.pth'))\n",
    "# 使用模型进行预测或进一步训练..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434616e-7854-4da3-8dd3-4da9a3757d59",
   "metadata": {},
   "source": [
    "&emsp;&emsp;4. 便于调试和分析：通过检查模型参数，可以对模型进行调试和分析。例如，可以打印出模型权重和偏置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7db152fc-7ad4-4249-b122-15d2a7b12ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.weight\n",
      "tensor([[-0.2898,  0.2839,  0.0169,  0.0477, -0.0595, -0.2568, -0.0884, -0.2903,\n",
      "         -0.1100, -0.1530],\n",
      "        [ 0.2284,  0.0527, -0.2718, -0.0059, -0.1315,  0.3001,  0.0876, -0.2056,\n",
      "         -0.1616, -0.0564]])\n",
      "fc.bias\n",
      "tensor([-0.1099,  0.0685])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        print(param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee465e3e-c846-40ef-a249-e3b7f622fd0f",
   "metadata": {},
   "source": [
    "### 练习二\n",
    "\n",
    "2. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9cbedb-dcf9-446e-84b6-85db9857985a",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ffc707-0da1-4e6a-820a-255252f77287",
   "metadata": {},
   "source": [
    "&emsp;&emsp;使用保存模型某层参数的办法，保存网络的前两层，然后再加载到新的网络中使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff833e9a-5835-4c99-8aed-47e70d4d3299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"定义 MLP 类。\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256) # 定义隐藏层，输入尺寸为20，输出尺寸为256。\n",
    "        self.output = nn.Linear(256, 10) # 定义输出层，输入尺寸为256，输出尺寸为10\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"定义前向传播函数。\"\"\"\n",
    "        # 使用 ReLU 激活函数，计算隐藏层和输出层的输出\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "class MLP_new(nn.Module):\n",
    "    \"\"\"定义 MLP_new 类。\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)  # 定义隐藏层，输入尺寸为 20，输出尺寸为 256。\n",
    "        self.output = nn.Linear(256, 10)  # 定义输出层，输入尺寸为 256，输出尺寸为 10。\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"定义前向传播函数。\"\"\"\n",
    "        # 使用 ReLU 激活函数，计算隐藏层和输出层的输出\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP() # 创建 MLP 的实例\n",
    "# 将隐藏层的参数保存到文件中。\n",
    "torch.save(net.hidden.state_dict(), 'mlp.hidden.params')\n",
    "\n",
    "clone = MLP_new() # 创建另一个 MLP 的实例。\n",
    "# 加载已保存的参数到克隆实例的隐藏层中。\n",
    "clone.hidden.load_state_dict(torch.load('mlp.hidden.params'))\n",
    "\n",
    "# 比较两个 MLP 示例的隐藏层权重是否相等，并输出结果\n",
    "print(clone.hidden.weight == net.hidden.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e8a6c-9643-40a8-b945-58b5777d50e1",
   "metadata": {},
   "source": [
    "### 练习三\n",
    "\n",
    "3. 如何同时保存网络架构和参数？需要对架构加上什么限制？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81130364-ceb5-4af1-ace4-2abf93ad8ffa",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在PyTorch中，可以使用`torch.save()`函数同时保存网络架构和参数。为了保存网络架构，需要将模型的结构定义在一个Python类中，并将该实例化为模型对象。此外，必须确保该类的构造函数不包含任何随机性质的操作，例如`dropout`层的随机丢弃率应该是固定的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4531ae9b-89c9-44e7-8e0a-422ab19cd678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"定义 MLP 类。\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256) # 定义隐藏层，输入尺寸为 20，输出尺寸为 256。\n",
    "        self.output = nn.Linear(256, 10) # 定义输出层，输入磁村为 256，输出尺寸为 10。\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"定义前向传播函数。\"\"\"\n",
    "        # 使用 ReLU 激活函数，计算隐藏层和输出层的输出\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "\n",
    "# 存储模型\n",
    "torch.save(net, 'model.pt')\n",
    "\n",
    "# 导入模型\n",
    "model = torch.load('model.pt')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad9386-6539-4c78-a8f5-5ab92aac89d0",
   "metadata": {},
   "source": [
    "[讲解了保存网络结构和参数；和只保存网络参数；这两种方法。](https://blog.csdn.net/huihui__huihui/article/details/107216659)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
