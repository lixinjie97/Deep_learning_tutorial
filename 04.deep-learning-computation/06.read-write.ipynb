{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637fd2da-44c9-49fc-95b0-37d456bbc6ec",
   "metadata": {},
   "source": [
    "# 读写文件\n",
    "\n",
    "到目前为止，我们讨论了如何处理数据，\n",
    "以及如何构建、训练和测试深度学习模型。\n",
    "然而，有时我们希望保存训练的模型，\n",
    "以备将来在各种环境中使用（比如在部署中进行预测）。\n",
    "此外，当运行一个耗时较长的训练过程时，\n",
    "最佳的做法是定期保存中间结果，\n",
    "以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。\n",
    "因此，现在是时候学习如何加载和存储权重向量和整个模型了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e47d1f-ba97-4b6f-bb59-82dc52dca87a",
   "metadata": {},
   "source": [
    "## (**加载和保存张量**)\n",
    "\n",
    "对于单个张量，我们可以直接调用`load`和`save`函数分别读写它们。\n",
    "这两个函数都要求我们提供一个名称，`save`要求将要保存的变量作为输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ffaf1a-61b7-4199-9eaa-bb0e1d975799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3b5ef-d6f7-4f14-9216-559ddcb8e37e",
   "metadata": {},
   "source": [
    "我们现在可以将存储在文件中的数据读回内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99896573-f66d-48e0-b67e-4bef1632630f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8805a0fc-2bd6-4cad-ad72-d8ae2d877318",
   "metadata": {},
   "source": [
    "我们可以[**存储一个张量列表，然后把它们读回内存。**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b9e0a6-2f77-4e91-b8fa-e43c32f54ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y], 'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf0794-056b-4a27-b0d7-a0d67d118b75",
   "metadata": {},
   "source": [
    "我们甚至可以(**写入或读取从字符串映射到张量的字典**)。\n",
    "当我们要读取或写入模型中的所有权重时，这很方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c5cb6b-4147-4f8a-97d6-e7fd1b5931c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c43104-2b6e-4bba-9cb7-2118e0d88206",
   "metadata": {},
   "source": [
    "## [**加载和保存模型参数**]\n",
    "\n",
    "保存单个权重向量（或其他张量）确实有用，\n",
    "但是如果我们想保存整个模型，并在以后加载它们，\n",
    "单独保存每个向量则会变得很麻烦。\n",
    "毕竟，我们可能有数百个参数散布在各处。\n",
    "因此，深度学习框架提供了内置函数来保存和加载整个网络。\n",
    "**需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。**\n",
    "例如，如果我们有一个3层多层感知机，我们需要单独指定架构。\n",
    "因为模型本身可以包含任意代码，所以模型本身难以序列化。\n",
    "因此，为了恢复模型，我们需要用代码生成架构，\n",
    "然后从磁盘加载参数。\n",
    "让我们从熟悉的多层感知机开始尝试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f26466-dc2b-43b5-a625-87cbc1d380c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.6704, -0.0873, -1.5169,  1.1367, -1.8229,  0.1768, -0.4015,  0.3436,\n",
       "          -1.3141,  0.2494,  0.9123, -2.3178,  0.3741, -1.3778,  1.0040, -0.4411,\n",
       "           0.2945, -1.9843, -0.8758, -0.8836],\n",
       "         [ 0.2729, -0.2969, -1.1340,  0.6454,  0.2003, -0.6047,  0.2793,  0.5907,\n",
       "           0.5478,  0.1890, -1.4201, -0.4658, -0.8422,  0.4994,  0.1606, -0.3161,\n",
       "           0.4686,  0.0990, -0.5713, -1.2930]]),\n",
       " tensor([[-0.2349,  0.3141,  0.0643, -0.5557, -0.0561,  0.0798,  0.0691,  0.5871,\n",
       "          -0.3742,  0.3844],\n",
       "         [-0.0560,  0.2043, -0.0851, -0.0547,  0.0564,  0.1259, -0.0427,  0.1011,\n",
       "           0.0191,  0.0592]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4603962-a4e0-4cf2-ad0f-beff9ad2956d",
   "metadata": {},
   "source": [
    "接下来，我们[**将模型的参数存储在一个叫做“mlp.params”的文件中。**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "607d1787-b4e8-4ea4-bac3-ea31f7bc3aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[ 0.2078,  0.0817, -0.0243,  ...,  0.1357,  0.0890, -0.0911],\n",
       "                      [-0.0420,  0.0313, -0.0831,  ..., -0.2114, -0.2186,  0.1301],\n",
       "                      [-0.1529, -0.1986,  0.0133,  ...,  0.0553, -0.1895,  0.1850],\n",
       "                      ...,\n",
       "                      [-0.0754,  0.2184,  0.0838,  ...,  0.1210, -0.2118, -0.0100],\n",
       "                      [-0.1751,  0.0602, -0.0281,  ...,  0.1957,  0.0483,  0.1417],\n",
       "                      [-0.0989, -0.0331, -0.0775,  ...,  0.0638,  0.1482,  0.1427]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([-2.3199e-02, -2.0725e-01, -1.9671e-01,  4.2320e-02,  2.1258e-01,\n",
       "                       1.8176e-01, -2.1460e-01,  1.8229e-01,  1.2728e-01,  2.1731e-01,\n",
       "                      -1.2655e-01, -1.6592e-02,  9.1806e-03, -1.6071e-01,  2.8347e-02,\n",
       "                       7.3912e-02,  1.9067e-01,  5.5350e-02,  7.9832e-02,  5.6686e-02,\n",
       "                      -2.2262e-01, -2.1531e-01, -1.1968e-01,  1.7603e-01, -1.5570e-01,\n",
       "                      -1.6734e-01, -1.4998e-01, -1.5076e-01, -4.9275e-02, -6.5828e-02,\n",
       "                       2.1356e-01, -4.1620e-03,  1.7685e-01,  1.5081e-01, -1.3371e-01,\n",
       "                      -1.9504e-02, -4.1895e-02,  2.1962e-01,  1.0832e-01,  1.2057e-01,\n",
       "                      -1.1309e-01,  1.3061e-01,  1.2841e-01, -3.8495e-02, -3.2587e-02,\n",
       "                       7.6807e-02,  1.0202e-01, -1.9790e-01, -2.0034e-01, -1.3179e-01,\n",
       "                       1.5554e-01,  1.5042e-01,  2.0124e-01, -7.4029e-02,  7.7946e-02,\n",
       "                       1.5034e-01, -1.6781e-01,  1.2818e-01, -1.7049e-01, -1.5571e-01,\n",
       "                       1.4118e-01, -1.6963e-01, -1.7979e-02,  3.1157e-02,  1.5395e-01,\n",
       "                      -2.0767e-01,  1.6719e-01, -1.3246e-01,  1.0066e-01,  1.9506e-01,\n",
       "                      -6.3530e-02, -7.1595e-02,  1.2610e-02,  7.7945e-02,  1.2685e-01,\n",
       "                      -1.2189e-01,  1.4533e-01, -1.2769e-01,  1.7685e-01, -1.2503e-01,\n",
       "                       2.6545e-02,  1.4030e-01, -1.7222e-02,  1.4984e-01, -1.2547e-01,\n",
       "                       7.5717e-02,  1.0608e-01,  6.4891e-02,  1.6289e-01,  2.2049e-01,\n",
       "                      -1.4309e-02, -2.3848e-02, -9.1300e-02, -1.6661e-01,  1.3850e-01,\n",
       "                      -1.0039e-01,  1.9269e-01,  6.2019e-02, -2.1123e-01, -9.1928e-02,\n",
       "                      -1.1318e-01,  1.4507e-01, -1.2645e-01, -1.4034e-01, -9.1112e-02,\n",
       "                      -1.7863e-01,  1.4787e-01,  1.9080e-01, -1.4194e-01,  9.2230e-02,\n",
       "                       1.9497e-01, -6.8815e-03,  1.5148e-01, -1.8017e-01, -5.1765e-02,\n",
       "                       2.3041e-03, -6.7038e-02,  2.6219e-03, -2.0548e-01, -6.3263e-02,\n",
       "                      -8.5760e-02, -1.9882e-01, -2.0503e-01,  1.8515e-01,  5.9695e-02,\n",
       "                      -9.9873e-02, -1.9449e-01,  6.1045e-02, -1.6280e-01, -1.3639e-01,\n",
       "                      -8.5503e-02, -8.7988e-02,  7.3968e-02,  1.9283e-01,  2.5534e-02,\n",
       "                      -1.4173e-01,  1.6119e-02, -1.1945e-01,  1.1420e-01,  1.7425e-01,\n",
       "                       2.0855e-02, -9.1902e-02,  6.2861e-02, -8.7579e-03,  2.1792e-01,\n",
       "                       1.6396e-02,  1.7182e-01,  1.1877e-01, -1.2963e-01,  1.2270e-02,\n",
       "                       2.5511e-02,  1.5428e-01,  1.1206e-01, -1.1991e-01, -1.8847e-01,\n",
       "                      -8.5353e-02, -1.5805e-01, -7.9017e-02, -2.1011e-01,  1.9269e-01,\n",
       "                      -1.8437e-01, -6.7232e-02, -7.4026e-04,  2.0757e-01, -1.1715e-01,\n",
       "                       7.2014e-02,  1.8474e-01, -2.0819e-01, -1.9202e-01,  2.3718e-02,\n",
       "                      -1.1181e-01,  3.5981e-03,  1.2644e-01, -2.1879e-02,  2.0499e-01,\n",
       "                      -9.3778e-02, -1.0590e-02,  1.0946e-02, -5.5161e-02, -5.4321e-02,\n",
       "                       1.8525e-01,  1.4651e-01,  9.2961e-02, -2.2250e-01, -1.9744e-01,\n",
       "                      -1.4253e-01, -3.8202e-02, -1.0267e-01,  4.6313e-02,  1.6090e-01,\n",
       "                       9.4569e-02,  4.5477e-02, -2.7747e-02, -6.9901e-02,  1.4124e-02,\n",
       "                      -1.7403e-01, -2.0324e-01, -7.9985e-02,  5.7817e-02,  1.0699e-01,\n",
       "                      -1.4348e-01, -1.4614e-01, -8.6954e-02, -8.0036e-02,  1.5239e-01,\n",
       "                       1.1515e-01,  1.5895e-01, -3.7496e-02,  8.4073e-02, -4.9562e-02,\n",
       "                       1.8805e-01,  1.9613e-01,  3.1426e-02,  2.1203e-01,  2.0783e-01,\n",
       "                      -1.9462e-01,  4.6353e-02, -1.9503e-01, -1.1706e-01, -7.7842e-03,\n",
       "                      -6.4724e-02, -9.1627e-02, -6.5492e-02,  7.8366e-02, -1.1678e-01,\n",
       "                      -9.7644e-03,  9.4711e-02,  1.9760e-01, -2.0849e-02,  1.2601e-02,\n",
       "                      -3.2033e-02,  5.7106e-02,  2.1658e-01, -1.7656e-01, -2.1206e-01,\n",
       "                      -1.0533e-01, -8.7613e-02,  2.0387e-01,  6.0505e-02,  1.0784e-01,\n",
       "                      -1.5902e-03,  1.9719e-01,  1.1882e-01, -7.2503e-02, -2.0992e-04,\n",
       "                      -5.6259e-02,  3.9484e-02,  2.1516e-01,  1.9811e-01,  9.5356e-02,\n",
       "                      -1.9475e-01, -2.0158e-01,  1.6047e-01,  2.1369e-01, -2.1449e-01,\n",
       "                      -1.9208e-01])),\n",
       "             ('output.weight',\n",
       "              tensor([[-0.0227,  0.0411, -0.0518,  ...,  0.0127,  0.0417,  0.0281],\n",
       "                      [-0.0162, -0.0208,  0.0342,  ..., -0.0194, -0.0380, -0.0453],\n",
       "                      [-0.0566, -0.0584, -0.0088,  ...,  0.0031,  0.0056,  0.0581],\n",
       "                      ...,\n",
       "                      [ 0.0229,  0.0486, -0.0166,  ...,  0.0483, -0.0356, -0.0453],\n",
       "                      [-0.0323,  0.0261,  0.0392,  ...,  0.0484, -0.0565, -0.0090],\n",
       "                      [-0.0538, -0.0485, -0.0137,  ..., -0.0053, -0.0515,  0.0582]])),\n",
       "             ('output.bias',\n",
       "              tensor([-0.0326,  0.0572, -0.0141, -0.0583, -0.0538,  0.0608, -0.0016,  0.0358,\n",
       "                      -0.0531, -0.0590]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d991cc49-776e-454e-b7a9-f0edaa0b2767",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c1856-79c5-4709-a4bc-5e146ddab6fa",
   "metadata": {},
   "source": [
    "为了恢复模型，我们[**实例化了原始多层感知机模型的一个备份。**]\n",
    "这里我们不需要随机初始化模型参数，而是(**直接读取文件中存储的参数。**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c54a0b-0d42-4100-ab6e-fbbfefc3739a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b0a47-f972-4eb7-93e5-36b144547c22",
   "metadata": {},
   "source": [
    "由于两个实例具有相同的模型参数，在输入相同的`X`时，\n",
    "两个实例的计算结果应该相同。\n",
    "让我们来验证一下。\n",
    "\n",
    "注：eval评估模式下dropout会被关掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61a52d2-7a21-4083-9abb-a809fe98d6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3073da-21bc-49fa-adf7-d1afc3c6467f",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* `save`和`load`函数可用于张量对象的文件读写。\n",
    "* 我们可以通过参数字典保存和加载网络的全部参数。\n",
    "* 保存架构必须在代码中完成，而不是在参数中完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dee652-2412-4a6e-a466-c1c087a72b01",
   "metadata": {},
   "source": [
    "## 练习\n",
    "\n",
    "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？\n",
    "1. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？\n",
    "1. 如何同时保存网络架构和参数？需要对架构加上什么限制？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84930b8-b6e9-451f-b104-5f082a0539f0",
   "metadata": {},
   "source": [
    "### 练习一\n",
    "\n",
    "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5685a62-3b5c-456f-bf38-b2082a1b126d",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e0373-07ad-4fc4-965a-b0003b0d23d0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;1.便于模型恢复和微调：存储模型参数可以在训练中断后继续训练，或者在新的数据集上进行微调，而无需从头开始训练。\n",
    "\n",
    "&emsp;&emsp;2.节省存储空间：相比于保存完整的模型结构，保存模型参数通常占用更少的存储空间，这在处理大型模型或存储空间受限的情况下尤为重要。\n",
    "\n",
    "&emsp;&emsp;3.便于共享和复现：存储模型参数可以方便地共享和复现已经训练好的模型，其他人可以直接加载这些参数并使用它们进行预测或进一步训练。\n",
    "\n",
    "&emsp;&emsp;4.便于调试和分析：通过检查和分析模型参数，可以更容易地诊断模型中存在的问题，并对模型进行调整和优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f78314-35c9-4d2a-8155-278027dd6cf5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;下面将以一个简单的例子具体说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5be55-7b8d-41b9-8f3c-567bcefc19ae",
   "metadata": {},
   "source": [
    "&emsp;&emsp;1. 便于模型恢复和微调：假设我们有一个简单的神经网络模型，我们可以使用 PyTorch 保存和加载模型参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2594c3b6-0753-460d-9598-459c3c10974b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# 保存模型参数\n",
    "torch.save(model.state_dict(), 'model_parameters.pth')\n",
    "\n",
    "# 加载模型参数进行微调\n",
    "model.load_state_dict(torch.load('model_parameters.pth'))\n",
    "# 继续训练或进行微调..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc4463-ccbc-424a-83cb-fc61adb9be9c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;2. 节省存储空间：在上述示例中，通过使用`torch.save(model.state_dict(), 'model_parameters.pth')`只保存模型参数，而不是整个模型，可以节省存储空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb434a-03ee-45e5-9544-e4c58e4229d0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;3. 便于共享和复现：保存模型参数后，可以将 `model_parameters.pth` 文件与他人共享。他们可以使用以下代码加载参数并复现模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac392bf1-6b9d-4e4e-92d5-65bf16a38eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleModel()\n",
    "model.load_state_dict(torch.load('model_parameters.pth'))\n",
    "# 使用模型进行预测或进一步训练..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434616e-7854-4da3-8dd3-4da9a3757d59",
   "metadata": {},
   "source": [
    "&emsp;&emsp;4. 便于调试和分析：通过检查模型参数，可以对模型进行调试和分析。例如，可以打印出模型权重和偏置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7db152fc-7ad4-4249-b122-15d2a7b12ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.weight\n",
      "tensor([[-1.2774e-01,  2.1785e-01, -3.8828e-06,  2.9046e-01,  1.6467e-01,\n",
      "         -3.0214e-02, -1.3911e-02,  2.2464e-01, -3.1618e-01, -1.2282e-01],\n",
      "        [ 2.1680e-01,  5.9495e-02, -1.3927e-03, -2.9732e-01, -2.0234e-01,\n",
      "         -1.0656e-01,  8.8981e-02,  6.3178e-02,  5.5092e-02, -2.4218e-02]])\n",
      "fc.bias\n",
      "tensor([0.0937, 0.0920])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        print(param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee465e3e-c846-40ef-a249-e3b7f622fd0f",
   "metadata": {},
   "source": [
    "### 练习二\n",
    "\n",
    "2. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9cbedb-dcf9-446e-84b6-85db9857985a",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ffc707-0da1-4e6a-820a-255252f77287",
   "metadata": {},
   "source": [
    "&emsp;&emsp;使用保存模型某层参数的办法，保存网络的前两层，然后再加载到新的网络中使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff833e9a-5835-4c99-8aed-47e70d4d3299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"定义 MLP 类。\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256) # 定义隐藏层，输入尺寸为20，输出尺寸为256。\n",
    "        self.output = nn.Linear(256, 10) # 定义输出层，输入尺寸为256，输出尺寸为10\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"定义前向传播函数。\"\"\"\n",
    "        # 使用 ReLU 激活函数，计算隐藏层和输出层的输出\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "class MLP_new(nn.Module):\n",
    "    \"\"\"定义 MLP_new 类。\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)  # 定义隐藏层，输入尺寸为 20，输出尺寸为 256。\n",
    "        self.output = nn.Linear(256, 10)  # 定义输出层，输入尺寸为 256，输出尺寸为 10。\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"定义前向传播函数。\"\"\"\n",
    "        # 使用 ReLU 激活函数，计算隐藏层和输出层的输出\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP() # 创建 MLP 的实例\n",
    "# 将隐藏层的参数保存到文件中。\n",
    "torch.save(net.hidden.state_dict(), 'mlp.hidden.params')\n",
    "\n",
    "clone = MLP_new() # 创建另一个 MLP 的实例。\n",
    "# 加载已保存的参数到克隆实例的隐藏层中。\n",
    "clone.hidden.load_state_dict(torch.load('mlp.hidden.params'))\n",
    "\n",
    "# 比较两个 MLP 示例的隐藏层权重是否相等，并输出结果\n",
    "print(clone.hidden.weight == net.hidden.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e8a6c-9643-40a8-b945-58b5777d50e1",
   "metadata": {},
   "source": [
    "### 练习三\n",
    "\n",
    "3. 如何同时保存网络架构和参数？需要对架构加上什么限制？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81130364-ceb5-4af1-ace4-2abf93ad8ffa",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在PyTorch中，可以使用`torch.save()`函数同时保存网络架构和参数。为了保存网络架构，需要将模型的结构定义在一个Python类中，并将该实例化为模型对象。此外，必须确保该类的构造函数不包含任何随机性质的操作，例如`dropout`层的随机丢弃率应该是固定的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4531ae9b-89c9-44e7-8e0a-422ab19cd678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[ 0.1919,  0.1739,  0.1791,  ...,  0.0264,  0.1204, -0.0649],\n",
       "                      [ 0.0598,  0.2070,  0.1452,  ..., -0.0704,  0.1981, -0.0343],\n",
       "                      [-0.1819,  0.1304, -0.1353,  ...,  0.1365,  0.0960,  0.1419],\n",
       "                      ...,\n",
       "                      [-0.0773, -0.2093, -0.0257,  ..., -0.0257, -0.1069, -0.1072],\n",
       "                      [ 0.0205,  0.0114,  0.1147,  ..., -0.0531, -0.1401,  0.0911],\n",
       "                      [ 0.0822, -0.1318,  0.1897,  ...,  0.1369, -0.0851, -0.1400]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([ 0.2213,  0.1411,  0.1608,  0.1866,  0.1896, -0.1128, -0.0291,  0.1449,\n",
       "                       0.1427,  0.1917, -0.1950,  0.0390,  0.1072, -0.1042, -0.1064,  0.1581,\n",
       "                       0.1348,  0.0556,  0.0827,  0.0391, -0.0792,  0.1127, -0.0209,  0.0501,\n",
       "                       0.0423, -0.0273, -0.1840,  0.1553, -0.1338,  0.0065, -0.1273,  0.1443,\n",
       "                       0.0163, -0.1397,  0.1582, -0.1474,  0.1049,  0.0824,  0.1544,  0.1514,\n",
       "                      -0.0943, -0.0377, -0.1041, -0.1087,  0.1613, -0.1418,  0.0509,  0.1533,\n",
       "                      -0.2185,  0.1585, -0.2007, -0.1529, -0.0878,  0.0189, -0.0026, -0.0727,\n",
       "                      -0.1377,  0.1014,  0.0843,  0.1573,  0.1887, -0.0326,  0.0613, -0.0005,\n",
       "                      -0.1980,  0.1534, -0.1367, -0.0729, -0.1140,  0.1789,  0.0559, -0.0249,\n",
       "                       0.0430, -0.0278,  0.1373, -0.1087, -0.0089, -0.0539, -0.1518,  0.1321,\n",
       "                       0.2012,  0.1138, -0.1731, -0.1621,  0.1854, -0.0633,  0.0742,  0.0660,\n",
       "                      -0.1747, -0.0119,  0.1480, -0.1241,  0.1703,  0.0346,  0.0178, -0.0944,\n",
       "                       0.1830,  0.1828, -0.0785,  0.1266,  0.1048, -0.1817, -0.0083,  0.0228,\n",
       "                       0.1441, -0.0315,  0.1620,  0.0466, -0.0390, -0.0557, -0.2152, -0.1986,\n",
       "                       0.0212, -0.0146, -0.1825,  0.0180,  0.1377, -0.1855, -0.0264,  0.0804,\n",
       "                       0.0841, -0.0221,  0.0522, -0.1103, -0.1948, -0.0851,  0.1838, -0.1943,\n",
       "                       0.0008,  0.0140, -0.2157, -0.0318,  0.0747,  0.1450, -0.1088, -0.1809,\n",
       "                       0.1904,  0.0441,  0.1962, -0.0003,  0.0829, -0.1236, -0.0908,  0.1902,\n",
       "                       0.1318, -0.0584, -0.2130,  0.1686,  0.0157,  0.1164, -0.1262, -0.0052,\n",
       "                       0.0636,  0.0792, -0.1920, -0.1953,  0.0715,  0.0479, -0.0707, -0.0171,\n",
       "                      -0.1011,  0.2038, -0.0354, -0.0391,  0.1012, -0.2095,  0.0539,  0.1078,\n",
       "                       0.2195, -0.0701, -0.1466, -0.0490,  0.1454, -0.2013,  0.0702, -0.0435,\n",
       "                      -0.0570, -0.0800,  0.1068, -0.1972, -0.0014,  0.0589,  0.0765,  0.0404,\n",
       "                      -0.1979,  0.0096, -0.0411,  0.0061, -0.1624,  0.1732,  0.0161, -0.1871,\n",
       "                      -0.1533, -0.0104, -0.1751,  0.1349,  0.1234, -0.1331, -0.1021, -0.1027,\n",
       "                       0.1621,  0.1200, -0.0263,  0.1003,  0.1029,  0.0265,  0.0255, -0.2231,\n",
       "                       0.0308,  0.0304, -0.1867, -0.1797,  0.0680, -0.1011,  0.1435, -0.0519,\n",
       "                      -0.0632,  0.1934,  0.1453, -0.1732,  0.2180, -0.1734,  0.1701, -0.0605,\n",
       "                      -0.2118, -0.0034,  0.2215, -0.0601, -0.1734,  0.1816,  0.1975, -0.1138,\n",
       "                       0.1037,  0.0227,  0.0119, -0.1816, -0.0949, -0.0438,  0.0278,  0.1003,\n",
       "                      -0.0748, -0.1146, -0.0278, -0.1442,  0.1451, -0.0821,  0.2211, -0.0844,\n",
       "                       0.1002, -0.1869,  0.1914,  0.0085, -0.0728, -0.1802, -0.1975, -0.0385])),\n",
       "             ('output.weight',\n",
       "              tensor([[-0.0278,  0.0405, -0.0428,  ...,  0.0563, -0.0589, -0.0574],\n",
       "                      [ 0.0210, -0.0043, -0.0214,  ...,  0.0553, -0.0096, -0.0295],\n",
       "                      [-0.0363,  0.0382, -0.0130,  ...,  0.0565, -0.0258,  0.0174],\n",
       "                      ...,\n",
       "                      [ 0.0216,  0.0439, -0.0271,  ...,  0.0092,  0.0403,  0.0594],\n",
       "                      [ 0.0572, -0.0589,  0.0060,  ...,  0.0360, -0.0304, -0.0321],\n",
       "                      [-0.0554,  0.0507,  0.0395,  ..., -0.0532, -0.0510, -0.0279]])),\n",
       "             ('output.bias',\n",
       "              tensor([ 0.0168,  0.0159,  0.0228,  0.0550,  0.0083,  0.0270,  0.0309, -0.0435,\n",
       "                      -0.0313, -0.0404]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"定义 MLP 类。\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256) # 定义隐藏层，输入尺寸为 20，输出尺寸为 256。\n",
    "        self.output = nn.Linear(256, 10) # 定义输出层，输入磁村为 256，输出尺寸为 10。\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"定义前向传播函数。\"\"\"\n",
    "        # 使用 ReLU 激活函数，计算隐藏层和输出层的输出\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "\n",
    "# 存储模型\n",
    "torch.save(net.state_dict(), 'model.pt')\n",
    "\n",
    "# 导入模型\n",
    "model = torch.load('model.pt')\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
