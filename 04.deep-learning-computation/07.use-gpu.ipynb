{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80508433-01d6-41c7-817b-a05858dbd91e",
   "metadata": {},
   "source": [
    "# GPU\n",
    "\n",
    "我们回顾了过去20年计算能力的快速增长。\n",
    "简而言之，自2000年以来，GPU性能每十年增长1000倍。\n",
    "\n",
    "本节，我们将讨论如何利用这种计算性能进行研究。\n",
    "首先是如何使用单个GPU，然后是如何使用多个GPU和多个服务器（具有多个GPU）。\n",
    "\n",
    "我们先看看如何使用单个NVIDIA GPU进行计算。\n",
    "首先，确保至少安装了一个NVIDIA GPU。\n",
    "然后，下载[NVIDIA驱动和CUDA](https://developer.nvidia.com/cuda-downloads)\n",
    "并按照提示设置适当的路径。\n",
    "当这些准备工作完成，就可以使用`nvidia-smi`命令来(**查看显卡信息。**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "865d4090-02c8-4929-8ba5-7dc3c3835e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep  2 16:58:16 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.01              Driver Version: 536.67       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 Ti     On  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   36C    P8               5W / 165W |   5980MiB / 16380MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        25      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A        35      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A        37      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A      1772      C   /python3.10                               N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ed5cb4-d5ba-43ea-9519-4bba6c5f4d0a",
   "metadata": {},
   "source": [
    "在PyTorch中，每个数组都有一个设备（device），\n",
    "我们通常将其称为环境（context）。\n",
    "默认情况下，所有变量和相关的计算都分配给CPU。\n",
    "有时环境可能是GPU。\n",
    "当我们跨多个服务器部署作业时，事情会变得更加棘手。\n",
    "通过智能地将数组分配给环境，\n",
    "我们可以最大限度地减少在设备之间传输数据的时间。\n",
    "例如，当在带有GPU的服务器上训练神经网络时，\n",
    "我们通常希望模型的参数在GPU上。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29fc5b3-0ea2-4175-b105-5eeb252969fc",
   "metadata": {},
   "source": [
    "要运行此部分中的程序，至少需要两个GPU。\n",
    "注意，对大多数桌面计算机来说，这可能是奢侈的，但在云中很容易获得。\n",
    "例如可以使用AWS EC2的多GPU实例。\n",
    "本书的其他章节大都不需要多个GPU，\n",
    "而本节只是为了展示数据如何在不同的设备之间传递。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9538b98f-34bb-4ac2-ae1b-1a78e9833d0f",
   "metadata": {},
   "source": [
    "## [**计算设备**]\n",
    "\n",
    "我们可以指定用于存储和计算的设备，如CPU和GPU。\n",
    "默认情况下，张量是在内存中创建的，然后使用CPU计算它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c3d505-ce1c-4ece-bd39-d9e976f74d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cuda'), device(type='cuda', index=1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f816d7-9370-43db-b1cc-29459967aa02",
   "metadata": {},
   "source": [
    "我们可以(**查询可用gpu的数量。**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a73919-445f-4f30-b9c8-df912ec96821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe481748-4d15-428a-894b-47ef3cdc8681",
   "metadata": {},
   "source": [
    "现在我们定义了两个方便的函数，\n",
    "[**这两个函数允许我们在不存在所需所有GPU的情况下运行代码。**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edeaee00-f557-4891-801c-2ada3d1815b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0),\n",
       " device(type='cpu'),\n",
       " [device(type='cuda', index=0)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gpus():\n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "              for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a1592-1299-4243-b936-7c0077567a69",
   "metadata": {},
   "source": [
    "## 张量与GPU\n",
    "\n",
    "我们可以[**查询张量所在的设备。**]\n",
    "默认情况下，张量是在CPU上创建的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83bd998c-c25d-48e2-ad42-1683302cb795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f25eab1-0bc6-43ff-94a7-86602494a573",
   "metadata": {},
   "source": [
    "需要注意的是，无论何时我们要对多个项进行操作，\n",
    "它们都必须在同一个设备上。\n",
    "例如，如果我们对两个张量求和，\n",
    "我们需要确保两个张量都位于同一个设备上，\n",
    "否则框架将不知道在哪里存储结果，甚至不知道在哪里执行计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fde435-b149-4a3a-8c09-6387ab07ec7f",
   "metadata": {},
   "source": [
    "### [**存储在GPU上**]\n",
    "\n",
    "有几种方法可以在GPU上存储张量。\n",
    "例如，我们可以在创建张量时指定存储设备。接\n",
    "下来，我们在第一个`gpu`上创建张量变量`X`。\n",
    "在GPU上创建的张量只消耗这个GPU的显存。\n",
    "我们可以使用`nvidia-smi`命令查看显存使用情况。\n",
    "一般来说，我们需要确保不创建超过GPU显存限制的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abda4897-fe46-4871-8fb1-708b6573eb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2, 3, device=try_gpu())\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c27c6c-079a-4eff-8d3c-cb4be14626b1",
   "metadata": {},
   "source": [
    "假设我们只有一个GPU，下面的代码将在(**CPU上创建一个随机张量。**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888a2bcb-68fc-4b17-8206-1d7313eab0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6486, 0.7242, 0.7647],\n",
       "        [0.6596, 0.4374, 0.2359]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.rand(2, 3, device=try_gpu(10))\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dccbee88-f058-443c-8efe-a3cce548c2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    Y + X\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70cc09-209a-4f45-8ee8-55fb688f38cd",
   "metadata": {},
   "source": [
    "**可以看到张量做运算必须在同一个设备上**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e818021-53de-4251-b2c4-89a5e88d6896",
   "metadata": {},
   "source": [
    "### 复制\n",
    "\n",
    "如果我们[**要计算`X + Y`，我们需要决定在哪里执行这个操作**]。\n",
    "例如，如下图所示，\n",
    "我们可以将`X`传输到CPU并在那里执行操作。\n",
    "*不要*简单地`X`加上`Y`，因为这会导致异常，\n",
    "运行时引擎不知道该怎么做：它在同一设备上找不到数据会导致失败。\n",
    "由于`Y`位于CPU上，所以我们需要将`X`移到那里，\n",
    "然后才能执行相加运算。\n",
    "\n",
    "![复制数据以在同一设备上执行操作](../assets/copyto.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f2d2985-dd55-4f9c-8e0d-129d4f3ec3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "Z = X.cpu()\n",
    "print(X)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1181e517-27c8-4682-90c0-508b1496a66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6486, 1.7242, 1.7647],\n",
       "        [1.6596, 1.4374, 1.2359]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y + Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493076b-2fd2-4a01-93ed-6b2b39c87f7a",
   "metadata": {},
   "source": [
    "假设变量`Z`已经存在CPU上。\n",
    "如果我们还是调用`Z.cpu()`会发生什么？\n",
    "它将返回`Z`，而不会复制并分配新内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2653df2-4d1b-4433-b512-e4245183e100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.cpu() is Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365cd580-8562-44a7-9448-5259de960ab9",
   "metadata": {},
   "source": [
    "### 旁注\n",
    "\n",
    "人们使用GPU来进行机器学习，因为单个GPU相对运行速度快。\n",
    "但是在设备（CPU、GPU和其他机器）之间传输数据比计算慢得多。\n",
    "这也使得并行化变得更加困难，因为我们必须等待数据被发送（或者接收），\n",
    "然后才能继续进行更多的操作。\n",
    "这就是为什么拷贝操作要格外小心。\n",
    "根据经验，多个小操作比一个大操作糟糕得多。\n",
    "此外，一次执行几个操作比代码中散布的许多单个操作要好得多。\n",
    "如果一个设备必须等待另一个设备才能执行其他操作，\n",
    "那么这样的操作可能会阻塞。\n",
    "这有点像排队订购咖啡，而不像通过电话预先订购：\n",
    "当客人到店的时候，咖啡已经准备好了。\n",
    "\n",
    "最后，当我们打印张量或将张量转换为NumPy格式时，\n",
    "如果数据不在内存中，框架会首先将其复制到内存中，\n",
    "这会导致额外的传输开销。\n",
    "更糟糕的是，它现在受制于全局解释器锁，使得一切都得等待Python完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e048fe0-7625-49bb-be1a-76abe1119779",
   "metadata": {},
   "source": [
    "## [**神经网络与GPU**]\n",
    "\n",
    "类似地，神经网络模型可以指定设备。\n",
    "下面的代码将模型参数放在GPU上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e60c01c9-e8d4-4bb0-a906-0e5c03ef0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(3, 1))\n",
    "net = net.to(device=try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c675891e-9df3-46bb-bf35-b8d4e33371c5",
   "metadata": {},
   "source": [
    "在接下来的几章中，\n",
    "我们将看到更多关于如何在GPU上运行模型的例子，\n",
    "因为它们将变得更加计算密集。\n",
    "\n",
    "当输入为GPU上的张量时，模型将在同一GPU上计算结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb62bc7-9d29-4d67-b56c-b1ba29ca2546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4917],\n",
       "        [0.4917]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eed9df-c090-4eac-8a95-90a7f65e9dbe",
   "metadata": {},
   "source": [
    "让我们(**确认模型参数存储在同一个GPU上。**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e4c2a9e-00fa-40b1-bd08-25b6264e5c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6726bbc-cd8b-49ac-82dc-361ce45e4f0c",
   "metadata": {},
   "source": [
    "总之，只要所有的数据和参数都在同一个设备上，\n",
    "我们就可以有效地学习模型。\n",
    "在下面的章节中，我们将看到几个这样的例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae68b221-f568-481a-b6e3-75c8b22d0f93",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* 我们可以指定用于存储和计算的设备，例如CPU或GPU。默认情况下，数据在主内存中创建，然后使用CPU进行计算。\n",
    "* 深度学习框架要求计算的所有输入数据都在同一设备上，无论是CPU还是GPU。\n",
    "* 不经意地移动数据可能会显著降低性能。一个典型的错误如下：计算GPU上每个小批量的损失，并在命令行中将其报告给用户（或将其记录在NumPy `ndarray`中）时，将触发全局解释器锁，从而使所有GPU阻塞。最好是为GPU内部的日志分配内存，并且只移动较大的日志。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e87384-479e-4fdf-a21c-afd65d0a0a5c",
   "metadata": {},
   "source": [
    "## 练习\n",
    "\n",
    "1. 尝试一个计算量更大的任务，比如大矩阵的乘法，看看CPU和GPU之间的速度差异。再试一个计算量很小的任务呢？\n",
    "1. 我们应该如何在GPU上读写模型参数？\n",
    "1. 测量计算1000个$100 \\times 100$矩阵的矩阵乘法所需的时间，并记录输出矩阵的Frobenius范数，一次记录一个结果，而不是在GPU上保存日志并仅传输最终结果。\n",
    "1. 测量同时在两个GPU上执行两个矩阵乘法与在一个GPU上按顺序执行两个矩阵乘法所需的时间。提示：应该看到近乎线性的缩放。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf0bdfc-5cac-439f-8995-a9ae6ca6dfdb",
   "metadata": {},
   "source": [
    "### 练习一\n",
    "\n",
    "1. 尝试一个计算量更大的任务，比如大矩阵的乘法，看看CPU和GPU之间的速度差异。再试一个计算量很小的任务呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a759f-811e-4dbb-9e34-6a6447e64c02",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213e24e-70b7-4427-9d11-30d2cc6ad210",
   "metadata": {},
   "source": [
    "&emsp;&emsp;计算量很大的任务：使用GPU速度明显更快。\n",
    "\n",
    "&emsp;&emsp;计算量很小的任务：CPU速度可能更快，因为数据传输到GPU需要时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d162e605-ac9b-4cd3-8451-b5a7ca32f351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu time cost: 3535.61ms\n",
      "gpu time cost: 14.99ms\n",
      "cpu time cost: 0.27ms\n",
      "gpu time cost: 7.5ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# 计算量较大的任务\n",
    "X = torch.rand((10000, 10000))\n",
    "Y = X.cuda(0)\n",
    "time_start = time.time()\n",
    "Z = torch.mm(X, X)\n",
    "time_end = time.time()\n",
    "print(f'cpu time cost: {round((time_end - time_start) * 1000, 2)}ms')\n",
    "time_start = time.time()\n",
    "Z = torch.mm(Y, Y)\n",
    "time_end = time.time()\n",
    "print(f'gpu time cost: {round((time_end - time_start) * 1000, 2)}ms')\n",
    "\n",
    "# 计算量很小的任务\n",
    "X = torch.rand((100, 100))\n",
    "Y = X.cuda(0)\n",
    "time_start = time.time()\n",
    "Z = torch.mm(X, X)\n",
    "time_end = time.time()\n",
    "print(f'cpu time cost: {round((time_end - time_start) * 1000, 2)}ms')\n",
    "time_start = time.time()\n",
    "Z = torch.mm(Y, Y)\n",
    "time_end = time.time()\n",
    "print(f'gpu time cost: {round((time_end - time_start) * 1000, 2)}ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46613d1f-91a0-49aa-824e-2bfa64147f5b",
   "metadata": {},
   "source": [
    "### 练习二\n",
    "\n",
    "2. 我们应该如何在GPU上读写模型参数？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c88fd3-83b7-469f-bd8b-cf0ef2d57568",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a3b01-5699-48c7-91a8-e087bf6a510e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;使用`net.to(device)`将模型迁移到GPU上，然后再按照之前的方法读写参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76b9bb80-11cf-4c37-9ff0-c5e63faaecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[-0.0624, -0.1344,  0.0151,  ...,  0.1243,  0.1772,  0.0309],\n",
       "                      [-0.1788, -0.1553,  0.0989,  ...,  0.1617,  0.0595, -0.1883],\n",
       "                      [ 0.0788, -0.0966,  0.2205,  ..., -0.0418, -0.1214, -0.1594],\n",
       "                      ...,\n",
       "                      [ 0.1584,  0.1121, -0.1025,  ..., -0.0763,  0.0542, -0.1017],\n",
       "                      [ 0.1038,  0.1475,  0.1085,  ..., -0.1003, -0.1595,  0.1483],\n",
       "                      [-0.0080, -0.0576, -0.0292,  ..., -0.0806,  0.1951,  0.1452]],\n",
       "                     device='cuda:0')),\n",
       "             ('hidden.bias',\n",
       "              tensor([-1.6871e-03,  1.8661e-02,  1.7551e-01,  1.3839e-01, -2.0080e-01,\n",
       "                       1.3110e-01,  1.8795e-01, -2.1238e-01, -3.4391e-02, -5.7520e-02,\n",
       "                      -1.8577e-01,  1.9450e-01, -2.0548e-01,  4.5557e-02, -1.3829e-01,\n",
       "                      -1.5399e-01, -5.7591e-02,  1.2907e-01,  6.7195e-03,  3.9955e-02,\n",
       "                       1.2995e-01,  1.6912e-01, -1.1916e-01,  7.4065e-02,  1.1882e-01,\n",
       "                       1.3333e-02, -5.0857e-02, -1.1126e-01,  1.8964e-01, -1.0607e-01,\n",
       "                      -3.3027e-02,  7.1066e-02,  1.9632e-02,  1.5816e-01,  2.0652e-01,\n",
       "                      -2.0678e-01, -2.1729e-01, -4.8162e-02, -1.2203e-01,  1.1151e-01,\n",
       "                      -2.0446e-01, -1.5148e-01, -1.3650e-01, -2.1853e-01, -1.1831e-01,\n",
       "                      -1.7107e-01,  1.9542e-01, -1.8152e-01, -9.3509e-02, -1.2746e-01,\n",
       "                       1.9952e-02,  1.1549e-01, -1.7219e-01, -1.6630e-02, -1.6197e-01,\n",
       "                       2.1507e-01, -1.8391e-01,  8.6758e-03,  1.8030e-01, -1.8219e-01,\n",
       "                      -1.2994e-01, -2.6968e-02, -2.0997e-01, -2.1425e-01,  2.3037e-02,\n",
       "                      -1.9346e-01, -1.3447e-01,  1.2710e-01,  1.3198e-01,  1.3249e-01,\n",
       "                       2.0324e-01, -1.6491e-01,  1.1396e-01, -2.2859e-02,  1.1711e-01,\n",
       "                      -1.7078e-01, -1.5323e-02, -4.3112e-02,  9.7632e-02,  1.9482e-01,\n",
       "                       1.9851e-01,  1.6541e-01,  8.1383e-02, -1.0064e-01,  2.3421e-02,\n",
       "                      -8.4946e-02,  1.0884e-01,  3.5837e-02,  8.2656e-02,  2.0719e-01,\n",
       "                       4.7535e-02, -2.0272e-01,  8.4113e-02, -1.0130e-01, -1.8296e-03,\n",
       "                      -7.9545e-02,  7.3979e-02, -1.2226e-02, -1.5543e-01,  5.7580e-02,\n",
       "                      -2.1701e-01,  7.5685e-02, -2.0550e-01, -1.5176e-01, -6.6261e-02,\n",
       "                       2.0801e-01, -8.1475e-02, -1.1639e-01, -1.3486e-01,  1.3719e-02,\n",
       "                      -1.6796e-01, -7.6824e-02, -6.2262e-02,  8.7951e-02,  1.3862e-01,\n",
       "                      -1.9692e-01,  9.7554e-02, -1.8426e-01,  4.3303e-02, -5.0335e-02,\n",
       "                      -1.5554e-01, -1.9955e-01,  1.0243e-01,  2.2152e-01,  2.0244e-01,\n",
       "                       9.7195e-02,  2.1935e-01,  7.8663e-03,  1.4693e-01, -1.8379e-01,\n",
       "                       7.2465e-02, -6.7805e-02,  1.1841e-01, -1.0132e-01, -1.1424e-01,\n",
       "                       1.5197e-02,  5.5450e-02,  1.8653e-01,  1.8248e-01, -2.0591e-01,\n",
       "                      -2.0554e-01, -1.9960e-01, -1.4544e-02, -2.0389e-01, -9.5551e-02,\n",
       "                      -1.2714e-01, -2.1828e-02, -1.9515e-01, -6.6572e-02, -1.4268e-01,\n",
       "                      -1.8767e-01,  1.3680e-01, -1.6421e-01,  1.4361e-01, -1.9048e-01,\n",
       "                       9.3727e-02, -5.5817e-03, -1.7624e-01,  2.2122e-01, -2.3455e-02,\n",
       "                       3.5987e-02, -7.9822e-02,  1.7956e-03,  9.5366e-02,  1.4159e-01,\n",
       "                      -4.7206e-02,  3.2021e-02, -8.7788e-03,  9.8645e-02,  1.9999e-01,\n",
       "                      -8.2704e-02, -6.3634e-02, -5.8169e-02, -2.0476e-02, -1.0811e-01,\n",
       "                       2.1490e-01,  8.2672e-02,  1.4728e-01,  1.9455e-01,  4.4164e-02,\n",
       "                      -4.6035e-02, -9.1706e-02, -1.7046e-01, -5.6363e-02,  2.0660e-01,\n",
       "                      -1.4319e-01,  7.9550e-02, -2.1452e-01, -8.1508e-02, -2.1601e-02,\n",
       "                       3.2563e-02, -2.0517e-01,  7.8084e-02, -5.9458e-02, -1.1124e-01,\n",
       "                       1.1258e-01,  8.4152e-02, -8.5156e-03, -4.7770e-02, -1.9090e-01,\n",
       "                       6.5519e-02,  4.4418e-02, -1.3097e-01, -1.4811e-01, -8.7002e-03,\n",
       "                      -1.6079e-01, -8.5958e-02,  5.2799e-02,  1.1496e-01, -1.0593e-01,\n",
       "                      -7.0050e-02, -8.5318e-02,  2.1675e-01,  5.7864e-03,  6.7504e-02,\n",
       "                       1.3907e-01, -3.2789e-02,  1.9168e-01,  6.1924e-02,  4.1010e-02,\n",
       "                      -1.7101e-01, -1.4172e-02,  1.0679e-01, -4.2546e-02, -1.1094e-01,\n",
       "                       1.3825e-01,  7.8264e-03, -4.0394e-02, -3.8197e-02, -5.8129e-02,\n",
       "                       1.6717e-01, -1.6939e-01,  6.2811e-02, -1.0964e-01,  1.2756e-01,\n",
       "                      -2.5057e-06, -9.5563e-02, -2.3939e-02, -8.3966e-02,  7.7632e-02,\n",
       "                       1.4754e-01, -3.3567e-02, -5.5385e-02,  7.3476e-02, -8.4796e-02,\n",
       "                       1.6317e-01,  6.9896e-02, -1.3018e-01, -9.7842e-02, -6.0362e-02,\n",
       "                       1.8808e-01, -1.2107e-01, -7.5143e-02, -1.0726e-01,  8.1305e-02,\n",
       "                       1.8552e-01], device='cuda:0')),\n",
       "             ('output.weight',\n",
       "              tensor([[-0.0381,  0.0322,  0.0015,  ..., -0.0277, -0.0487,  0.0132],\n",
       "                      [-0.0290,  0.0442,  0.0551,  ...,  0.0102,  0.0484,  0.0211],\n",
       "                      [-0.0217, -0.0113, -0.0236,  ...,  0.0242,  0.0250,  0.0051],\n",
       "                      ...,\n",
       "                      [ 0.0162, -0.0006,  0.0201,  ..., -0.0157, -0.0043, -0.0259],\n",
       "                      [-0.0137, -0.0166, -0.0080,  ..., -0.0555,  0.0375, -0.0286],\n",
       "                      [ 0.0121, -0.0273, -0.0293,  ...,  0.0428,  0.0389,  0.0376]],\n",
       "                     device='cuda:0')),\n",
       "             ('output.bias',\n",
       "              tensor([-0.0391, -0.0341,  0.0510, -0.0368,  0.0557, -0.0550, -0.0568,  0.0310,\n",
       "                       0.0313,  0.0404], device='cuda:0'))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"定义 MLP 类\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256) # 定义隐藏层，输入尺寸为 20，输出尺寸为 256。\n",
    "        self.output = nn.Linear(256, 10) # 定义输出层，输入尺寸为 256，输出尺寸为 10。\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"定义前向传播函数。\"\"\"\n",
    "        # 使用 ReLU 激活函数，计算隐藏层和输出层的输出\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "# 选择GPU，没有GPU就选CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 创建模型实例对象\n",
    "net = MLP()\n",
    "# 将模型参数传输到GPU上\n",
    "net.to(device)\n",
    "# 访问模型参数\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e557a-0e50-4ddf-99be-07511cd43c92",
   "metadata": {},
   "source": [
    "### 练习三\n",
    "\n",
    "3. 测量计算1000个$100 \\times 100$矩阵的矩阵乘法所需的时间，并记录输出矩阵的Frobenius范数，一次记录一个结果，而不是在GPU上保存日志并仅传输最终结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab33b6f7-e65f-4d9a-9c0b-821b27501e29",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad4ca8-29e0-44da-b531-c02380d84a3e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;中文版翻译有点问题，英文原版这句话是：\n",
    "\n",
    ">Measure the time it takes to compute 1000 matrix-matrix multiplications of $100×100$ matrices and log the Frobenius norm of the output matrix one result at a time vs. keeping a log on the GPU and transferring only the final result.\n",
    "\n",
    "&emsp;&emsp;所以这道题的本质还是希望我们做个比较。\n",
    "\n",
    "&emsp;&emsp;实验一：仅记录1000次$100×100$矩阵相乘所用的时间，不需要打印Frobenius范数。\n",
    "\n",
    "&emsp;&emsp;实验二：记录1000次$100×100$矩阵相乘所用的时间，并打印Frobenius范数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78ce99d6-0863-48a9-b5a8-2e50d25815ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.04613924026489258\n",
      "tensor(1447.6189, device='cuda:0')\n",
      "tensor(1385.6562, device='cuda:0')\n",
      "tensor(1406.6793, device='cuda:0')\n",
      "tensor(1431.3994, device='cuda:0')\n",
      "tensor(1366.3093, device='cuda:0')\n",
      "tensor(1419.9310, device='cuda:0')\n",
      "tensor(1374.8992, device='cuda:0')\n",
      "tensor(1402.1981, device='cuda:0')\n",
      "tensor(1396.1688, device='cuda:0')\n",
      "tensor(1405.4099, device='cuda:0')\n",
      "tensor(1375.2433, device='cuda:0')\n",
      "tensor(1419.0358, device='cuda:0')\n",
      "tensor(1429.8921, device='cuda:0')\n",
      "tensor(1376.8198, device='cuda:0')\n",
      "tensor(1397.0930, device='cuda:0')\n",
      "tensor(1407.5486, device='cuda:0')\n",
      "tensor(1426.8495, device='cuda:0')\n",
      "tensor(1475.9581, device='cuda:0')\n",
      "tensor(1434.7404, device='cuda:0')\n",
      "tensor(1421.9675, device='cuda:0')\n",
      "tensor(1382.2583, device='cuda:0')\n",
      "tensor(1393.7953, device='cuda:0')\n",
      "tensor(1388.4827, device='cuda:0')\n",
      "tensor(1412.3043, device='cuda:0')\n",
      "tensor(1403.5680, device='cuda:0')\n",
      "tensor(1446.2697, device='cuda:0')\n",
      "tensor(1408.5104, device='cuda:0')\n",
      "tensor(1400.5610, device='cuda:0')\n",
      "tensor(1454.0824, device='cuda:0')\n",
      "tensor(1444.7782, device='cuda:0')\n",
      "tensor(1479.7081, device='cuda:0')\n",
      "tensor(1414.3693, device='cuda:0')\n",
      "tensor(1375.1392, device='cuda:0')\n",
      "tensor(1434.6594, device='cuda:0')\n",
      "tensor(1438.3734, device='cuda:0')\n",
      "tensor(1396.0696, device='cuda:0')\n",
      "tensor(1392.7986, device='cuda:0')\n",
      "tensor(1408.2900, device='cuda:0')\n",
      "tensor(1427.9963, device='cuda:0')\n",
      "tensor(1405.1376, device='cuda:0')\n",
      "tensor(1465.2903, device='cuda:0')\n",
      "tensor(1398.8118, device='cuda:0')\n",
      "tensor(1409.3156, device='cuda:0')\n",
      "tensor(1406.4459, device='cuda:0')\n",
      "tensor(1393.4735, device='cuda:0')\n",
      "tensor(1427.1523, device='cuda:0')\n",
      "tensor(1410.8076, device='cuda:0')\n",
      "tensor(1391.8889, device='cuda:0')\n",
      "tensor(1408.1239, device='cuda:0')\n",
      "tensor(1422.9369, device='cuda:0')\n",
      "tensor(1420.4624, device='cuda:0')\n",
      "tensor(1443.4912, device='cuda:0')\n",
      "tensor(1425.6694, device='cuda:0')\n",
      "tensor(1417.1661, device='cuda:0')\n",
      "tensor(1426.9731, device='cuda:0')\n",
      "tensor(1427.9486, device='cuda:0')\n",
      "tensor(1400.6339, device='cuda:0')\n",
      "tensor(1396.6912, device='cuda:0')\n",
      "tensor(1449.5725, device='cuda:0')\n",
      "tensor(1390.7173, device='cuda:0')\n",
      "tensor(1397.7948, device='cuda:0')\n",
      "tensor(1383.3596, device='cuda:0')\n",
      "tensor(1404.5732, device='cuda:0')\n",
      "tensor(1418.6354, device='cuda:0')\n",
      "tensor(1445.7057, device='cuda:0')\n",
      "tensor(1412.4456, device='cuda:0')\n",
      "tensor(1425.9004, device='cuda:0')\n",
      "tensor(1424.9269, device='cuda:0')\n",
      "tensor(1420.7780, device='cuda:0')\n",
      "tensor(1421.2922, device='cuda:0')\n",
      "tensor(1442.4551, device='cuda:0')\n",
      "tensor(1436.5892, device='cuda:0')\n",
      "tensor(1392.2988, device='cuda:0')\n",
      "tensor(1399.4022, device='cuda:0')\n",
      "tensor(1402.8923, device='cuda:0')\n",
      "tensor(1409.3301, device='cuda:0')\n",
      "tensor(1406.3453, device='cuda:0')\n",
      "tensor(1408.9749, device='cuda:0')\n",
      "tensor(1386.5704, device='cuda:0')\n",
      "tensor(1406.3130, device='cuda:0')\n",
      "tensor(1420.9111, device='cuda:0')\n",
      "tensor(1434.2303, device='cuda:0')\n",
      "tensor(1434.9519, device='cuda:0')\n",
      "tensor(1447.8798, device='cuda:0')\n",
      "tensor(1434.0175, device='cuda:0')\n",
      "tensor(1462.5656, device='cuda:0')\n",
      "tensor(1406.0394, device='cuda:0')\n",
      "tensor(1405.0872, device='cuda:0')\n",
      "tensor(1380.8079, device='cuda:0')\n",
      "tensor(1359.3586, device='cuda:0')\n",
      "tensor(1393.6680, device='cuda:0')\n",
      "tensor(1429.4033, device='cuda:0')\n",
      "tensor(1415.7479, device='cuda:0')\n",
      "tensor(1388.2201, device='cuda:0')\n",
      "tensor(1398.2017, device='cuda:0')\n",
      "tensor(1427.9967, device='cuda:0')\n",
      "tensor(1444.5792, device='cuda:0')\n",
      "tensor(1415.9363, device='cuda:0')\n",
      "tensor(1401.1782, device='cuda:0')\n",
      "tensor(1444.0175, device='cuda:0')\n",
      "tensor(1399.2356, device='cuda:0')\n",
      "tensor(1413.9097, device='cuda:0')\n",
      "tensor(1415.5017, device='cuda:0')\n",
      "tensor(1426.3995, device='cuda:0')\n",
      "tensor(1458.1749, device='cuda:0')\n",
      "tensor(1433.2341, device='cuda:0')\n",
      "tensor(1447.6462, device='cuda:0')\n",
      "tensor(1404.7241, device='cuda:0')\n",
      "tensor(1436.0452, device='cuda:0')\n",
      "tensor(1409.8810, device='cuda:0')\n",
      "tensor(1428.8073, device='cuda:0')\n",
      "tensor(1421.1005, device='cuda:0')\n",
      "tensor(1417.9072, device='cuda:0')\n",
      "tensor(1432.1008, device='cuda:0')\n",
      "tensor(1381.1444, device='cuda:0')\n",
      "tensor(1395.3599, device='cuda:0')\n",
      "tensor(1415.5068, device='cuda:0')\n",
      "tensor(1425.6313, device='cuda:0')\n",
      "tensor(1418.3798, device='cuda:0')\n",
      "tensor(1422.7933, device='cuda:0')\n",
      "tensor(1401.3054, device='cuda:0')\n",
      "tensor(1389.8113, device='cuda:0')\n",
      "tensor(1419.7188, device='cuda:0')\n",
      "tensor(1398.9342, device='cuda:0')\n",
      "tensor(1379.1774, device='cuda:0')\n",
      "tensor(1405.9084, device='cuda:0')\n",
      "tensor(1408.3563, device='cuda:0')\n",
      "tensor(1385.0455, device='cuda:0')\n",
      "tensor(1395.7869, device='cuda:0')\n",
      "tensor(1415.6388, device='cuda:0')\n",
      "tensor(1459.4677, device='cuda:0')\n",
      "tensor(1413.6394, device='cuda:0')\n",
      "tensor(1417.5221, device='cuda:0')\n",
      "tensor(1391.8953, device='cuda:0')\n",
      "tensor(1461.1051, device='cuda:0')\n",
      "tensor(1397.2821, device='cuda:0')\n",
      "tensor(1440.1129, device='cuda:0')\n",
      "tensor(1456.8041, device='cuda:0')\n",
      "tensor(1414.0603, device='cuda:0')\n",
      "tensor(1372.2058, device='cuda:0')\n",
      "tensor(1401.5154, device='cuda:0')\n",
      "tensor(1404.9696, device='cuda:0')\n",
      "tensor(1405.4832, device='cuda:0')\n",
      "tensor(1414.6244, device='cuda:0')\n",
      "tensor(1392.8687, device='cuda:0')\n",
      "tensor(1392.9926, device='cuda:0')\n",
      "tensor(1448.9972, device='cuda:0')\n",
      "tensor(1357.0946, device='cuda:0')\n",
      "tensor(1432.2722, device='cuda:0')\n",
      "tensor(1396.8657, device='cuda:0')\n",
      "tensor(1419.8466, device='cuda:0')\n",
      "tensor(1422.1902, device='cuda:0')\n",
      "tensor(1428.5195, device='cuda:0')\n",
      "tensor(1394.8782, device='cuda:0')\n",
      "tensor(1423.2667, device='cuda:0')\n",
      "tensor(1403.4529, device='cuda:0')\n",
      "tensor(1406.5897, device='cuda:0')\n",
      "tensor(1402.5839, device='cuda:0')\n",
      "tensor(1406.2040, device='cuda:0')\n",
      "tensor(1431.2094, device='cuda:0')\n",
      "tensor(1427.0312, device='cuda:0')\n",
      "tensor(1434.5779, device='cuda:0')\n",
      "tensor(1436.8236, device='cuda:0')\n",
      "tensor(1379.4165, device='cuda:0')\n",
      "tensor(1414.3831, device='cuda:0')\n",
      "tensor(1463.1257, device='cuda:0')\n",
      "tensor(1424.3578, device='cuda:0')\n",
      "tensor(1435.0315, device='cuda:0')\n",
      "tensor(1387.7144, device='cuda:0')\n",
      "tensor(1447.5790, device='cuda:0')\n",
      "tensor(1388.8033, device='cuda:0')\n",
      "tensor(1420.0603, device='cuda:0')\n",
      "tensor(1431.4452, device='cuda:0')\n",
      "tensor(1405.9852, device='cuda:0')\n",
      "tensor(1401.5409, device='cuda:0')\n",
      "tensor(1434.0430, device='cuda:0')\n",
      "tensor(1452.3466, device='cuda:0')\n",
      "tensor(1423.9595, device='cuda:0')\n",
      "tensor(1427.3835, device='cuda:0')\n",
      "tensor(1466.5293, device='cuda:0')\n",
      "tensor(1411.2594, device='cuda:0')\n",
      "tensor(1400.8992, device='cuda:0')\n",
      "tensor(1440.6810, device='cuda:0')\n",
      "tensor(1409.4565, device='cuda:0')\n",
      "tensor(1417.5610, device='cuda:0')\n",
      "tensor(1430.1183, device='cuda:0')\n",
      "tensor(1405.4613, device='cuda:0')\n",
      "tensor(1414.0403, device='cuda:0')\n",
      "tensor(1429.7380, device='cuda:0')\n",
      "tensor(1438.1649, device='cuda:0')\n",
      "tensor(1442.6857, device='cuda:0')\n",
      "tensor(1427.9929, device='cuda:0')\n",
      "tensor(1396.3682, device='cuda:0')\n",
      "tensor(1432.8597, device='cuda:0')\n",
      "tensor(1400.5300, device='cuda:0')\n",
      "tensor(1429.1091, device='cuda:0')\n",
      "tensor(1405.6832, device='cuda:0')\n",
      "tensor(1436.0270, device='cuda:0')\n",
      "tensor(1415.0479, device='cuda:0')\n",
      "tensor(1334.0731, device='cuda:0')\n",
      "tensor(1423.3746, device='cuda:0')\n",
      "tensor(1383.5668, device='cuda:0')\n",
      "tensor(1377.7821, device='cuda:0')\n",
      "tensor(1414.6356, device='cuda:0')\n",
      "tensor(1420.8756, device='cuda:0')\n",
      "tensor(1407.5145, device='cuda:0')\n",
      "tensor(1407.3458, device='cuda:0')\n",
      "tensor(1426.2175, device='cuda:0')\n",
      "tensor(1407.6956, device='cuda:0')\n",
      "tensor(1412.5377, device='cuda:0')\n",
      "tensor(1405.1156, device='cuda:0')\n",
      "tensor(1420.2661, device='cuda:0')\n",
      "tensor(1417.9126, device='cuda:0')\n",
      "tensor(1413.4911, device='cuda:0')\n",
      "tensor(1460.7251, device='cuda:0')\n",
      "tensor(1406.5195, device='cuda:0')\n",
      "tensor(1431.1925, device='cuda:0')\n",
      "tensor(1423.4795, device='cuda:0')\n",
      "tensor(1410.3019, device='cuda:0')\n",
      "tensor(1466.0692, device='cuda:0')\n",
      "tensor(1402.3105, device='cuda:0')\n",
      "tensor(1434.2720, device='cuda:0')\n",
      "tensor(1419.4752, device='cuda:0')\n",
      "tensor(1401.7472, device='cuda:0')\n",
      "tensor(1407.9082, device='cuda:0')\n",
      "tensor(1420.6886, device='cuda:0')\n",
      "tensor(1376.2948, device='cuda:0')\n",
      "tensor(1393.6548, device='cuda:0')\n",
      "tensor(1410.1427, device='cuda:0')\n",
      "tensor(1384.1968, device='cuda:0')\n",
      "tensor(1387.5061, device='cuda:0')\n",
      "tensor(1410.4583, device='cuda:0')\n",
      "tensor(1387.7623, device='cuda:0')\n",
      "tensor(1460.0153, device='cuda:0')\n",
      "tensor(1371.2537, device='cuda:0')\n",
      "tensor(1473.3297, device='cuda:0')\n",
      "tensor(1415.2323, device='cuda:0')\n",
      "tensor(1410.8635, device='cuda:0')\n",
      "tensor(1411.6785, device='cuda:0')\n",
      "tensor(1419.5211, device='cuda:0')\n",
      "tensor(1404.6211, device='cuda:0')\n",
      "tensor(1448.8315, device='cuda:0')\n",
      "tensor(1368.8284, device='cuda:0')\n",
      "tensor(1444.1622, device='cuda:0')\n",
      "tensor(1409.2289, device='cuda:0')\n",
      "tensor(1409.3589, device='cuda:0')\n",
      "tensor(1407.2493, device='cuda:0')\n",
      "tensor(1367.8082, device='cuda:0')\n",
      "tensor(1409.4812, device='cuda:0')\n",
      "tensor(1430.2838, device='cuda:0')\n",
      "tensor(1433.4150, device='cuda:0')\n",
      "tensor(1381.6001, device='cuda:0')\n",
      "tensor(1487.8629, device='cuda:0')\n",
      "tensor(1413.2242, device='cuda:0')\n",
      "tensor(1418.6617, device='cuda:0')\n",
      "tensor(1430.6223, device='cuda:0')\n",
      "tensor(1418.7600, device='cuda:0')\n",
      "tensor(1454.1621, device='cuda:0')\n",
      "tensor(1427.9781, device='cuda:0')\n",
      "tensor(1387.7203, device='cuda:0')\n",
      "tensor(1424.3147, device='cuda:0')\n",
      "tensor(1435.6781, device='cuda:0')\n",
      "tensor(1420.2815, device='cuda:0')\n",
      "tensor(1417.3379, device='cuda:0')\n",
      "tensor(1416.3768, device='cuda:0')\n",
      "tensor(1409.7008, device='cuda:0')\n",
      "tensor(1393.1825, device='cuda:0')\n",
      "tensor(1422.7922, device='cuda:0')\n",
      "tensor(1421.5354, device='cuda:0')\n",
      "tensor(1391.4648, device='cuda:0')\n",
      "tensor(1396.3843, device='cuda:0')\n",
      "tensor(1403.5095, device='cuda:0')\n",
      "tensor(1410.9945, device='cuda:0')\n",
      "tensor(1411.1450, device='cuda:0')\n",
      "tensor(1422.4989, device='cuda:0')\n",
      "tensor(1401.0876, device='cuda:0')\n",
      "tensor(1382.5614, device='cuda:0')\n",
      "tensor(1413.7543, device='cuda:0')\n",
      "tensor(1376.3296, device='cuda:0')\n",
      "tensor(1389.8615, device='cuda:0')\n",
      "tensor(1435.4677, device='cuda:0')\n",
      "tensor(1392.7047, device='cuda:0')\n",
      "tensor(1438.2266, device='cuda:0')\n",
      "tensor(1390.0227, device='cuda:0')\n",
      "tensor(1435.0422, device='cuda:0')\n",
      "tensor(1456.3331, device='cuda:0')\n",
      "tensor(1442.6447, device='cuda:0')\n",
      "tensor(1441.5826, device='cuda:0')\n",
      "tensor(1413.5811, device='cuda:0')\n",
      "tensor(1386.5679, device='cuda:0')\n",
      "tensor(1393.2504, device='cuda:0')\n",
      "tensor(1424.1996, device='cuda:0')\n",
      "tensor(1422.5803, device='cuda:0')\n",
      "tensor(1405.7212, device='cuda:0')\n",
      "tensor(1447.8507, device='cuda:0')\n",
      "tensor(1416.1001, device='cuda:0')\n",
      "tensor(1435.8033, device='cuda:0')\n",
      "tensor(1443.3643, device='cuda:0')\n",
      "tensor(1442.9583, device='cuda:0')\n",
      "tensor(1407.8134, device='cuda:0')\n",
      "tensor(1385.5348, device='cuda:0')\n",
      "tensor(1367.5673, device='cuda:0')\n",
      "tensor(1415.5082, device='cuda:0')\n",
      "tensor(1378.8788, device='cuda:0')\n",
      "tensor(1440.5405, device='cuda:0')\n",
      "tensor(1434.4530, device='cuda:0')\n",
      "tensor(1387.2245, device='cuda:0')\n",
      "tensor(1431.1002, device='cuda:0')\n",
      "tensor(1430.0476, device='cuda:0')\n",
      "tensor(1454.5521, device='cuda:0')\n",
      "tensor(1448.3959, device='cuda:0')\n",
      "tensor(1408.1575, device='cuda:0')\n",
      "tensor(1420.0292, device='cuda:0')\n",
      "tensor(1434.4705, device='cuda:0')\n",
      "tensor(1424.3478, device='cuda:0')\n",
      "tensor(1381.1896, device='cuda:0')\n",
      "tensor(1396.7642, device='cuda:0')\n",
      "tensor(1417.7440, device='cuda:0')\n",
      "tensor(1425.8717, device='cuda:0')\n",
      "tensor(1415.6301, device='cuda:0')\n",
      "tensor(1415.0931, device='cuda:0')\n",
      "tensor(1418.3401, device='cuda:0')\n",
      "tensor(1407.5486, device='cuda:0')\n",
      "tensor(1419.7770, device='cuda:0')\n",
      "tensor(1387.1467, device='cuda:0')\n",
      "tensor(1434.1620, device='cuda:0')\n",
      "tensor(1403.2312, device='cuda:0')\n",
      "tensor(1387.6022, device='cuda:0')\n",
      "tensor(1376.6313, device='cuda:0')\n",
      "tensor(1436.4506, device='cuda:0')\n",
      "tensor(1408.5656, device='cuda:0')\n",
      "tensor(1424.9799, device='cuda:0')\n",
      "tensor(1421.4476, device='cuda:0')\n",
      "tensor(1423.3534, device='cuda:0')\n",
      "tensor(1409.7043, device='cuda:0')\n",
      "tensor(1423.9176, device='cuda:0')\n",
      "tensor(1444.2681, device='cuda:0')\n",
      "tensor(1449.4807, device='cuda:0')\n",
      "tensor(1430.4237, device='cuda:0')\n",
      "tensor(1414.3208, device='cuda:0')\n",
      "tensor(1453.5767, device='cuda:0')\n",
      "tensor(1422.7976, device='cuda:0')\n",
      "tensor(1434.0370, device='cuda:0')\n",
      "tensor(1425.1147, device='cuda:0')\n",
      "tensor(1436.2332, device='cuda:0')\n",
      "tensor(1462.8500, device='cuda:0')\n",
      "tensor(1390.3336, device='cuda:0')\n",
      "tensor(1428.2410, device='cuda:0')\n",
      "tensor(1427.8059, device='cuda:0')\n",
      "tensor(1446.6893, device='cuda:0')\n",
      "tensor(1415.1152, device='cuda:0')\n",
      "tensor(1409.7593, device='cuda:0')\n",
      "tensor(1394.6023, device='cuda:0')\n",
      "tensor(1382.3708, device='cuda:0')\n",
      "tensor(1411.0320, device='cuda:0')\n",
      "tensor(1455.9451, device='cuda:0')\n",
      "tensor(1453.4587, device='cuda:0')\n",
      "tensor(1427.5601, device='cuda:0')\n",
      "tensor(1449.4137, device='cuda:0')\n",
      "tensor(1416.9580, device='cuda:0')\n",
      "tensor(1429.8043, device='cuda:0')\n",
      "tensor(1417.1746, device='cuda:0')\n",
      "tensor(1407.4149, device='cuda:0')\n",
      "tensor(1417.2181, device='cuda:0')\n",
      "tensor(1370.3600, device='cuda:0')\n",
      "tensor(1431.3989, device='cuda:0')\n",
      "tensor(1415.2805, device='cuda:0')\n",
      "tensor(1413.7308, device='cuda:0')\n",
      "tensor(1422.7443, device='cuda:0')\n",
      "tensor(1425.9152, device='cuda:0')\n",
      "tensor(1415.2255, device='cuda:0')\n",
      "tensor(1387.1139, device='cuda:0')\n",
      "tensor(1422.2205, device='cuda:0')\n",
      "tensor(1410.8629, device='cuda:0')\n",
      "tensor(1385.8036, device='cuda:0')\n",
      "tensor(1423.0011, device='cuda:0')\n",
      "tensor(1443.2673, device='cuda:0')\n",
      "tensor(1393.0851, device='cuda:0')\n",
      "tensor(1463.8329, device='cuda:0')\n",
      "tensor(1460.7673, device='cuda:0')\n",
      "tensor(1422.0778, device='cuda:0')\n",
      "tensor(1392.4095, device='cuda:0')\n",
      "tensor(1415.8630, device='cuda:0')\n",
      "tensor(1406.2532, device='cuda:0')\n",
      "tensor(1448.1576, device='cuda:0')\n",
      "tensor(1401.3582, device='cuda:0')\n",
      "tensor(1418.7136, device='cuda:0')\n",
      "tensor(1429.8501, device='cuda:0')\n",
      "tensor(1403.7830, device='cuda:0')\n",
      "tensor(1408.8635, device='cuda:0')\n",
      "tensor(1438.7349, device='cuda:0')\n",
      "tensor(1434.9520, device='cuda:0')\n",
      "tensor(1415.8910, device='cuda:0')\n",
      "tensor(1403.1154, device='cuda:0')\n",
      "tensor(1414.6654, device='cuda:0')\n",
      "tensor(1435.0916, device='cuda:0')\n",
      "tensor(1414.4856, device='cuda:0')\n",
      "tensor(1401.9957, device='cuda:0')\n",
      "tensor(1415.8435, device='cuda:0')\n",
      "tensor(1407.2634, device='cuda:0')\n",
      "tensor(1435.7726, device='cuda:0')\n",
      "tensor(1415.0892, device='cuda:0')\n",
      "tensor(1418.1969, device='cuda:0')\n",
      "tensor(1434.6240, device='cuda:0')\n",
      "tensor(1405.8901, device='cuda:0')\n",
      "tensor(1450.2920, device='cuda:0')\n",
      "tensor(1415.0684, device='cuda:0')\n",
      "tensor(1432.1078, device='cuda:0')\n",
      "tensor(1413.7642, device='cuda:0')\n",
      "tensor(1396.9408, device='cuda:0')\n",
      "tensor(1412.7319, device='cuda:0')\n",
      "tensor(1404.1244, device='cuda:0')\n",
      "tensor(1429.4255, device='cuda:0')\n",
      "tensor(1385.6709, device='cuda:0')\n",
      "tensor(1424.9784, device='cuda:0')\n",
      "tensor(1396.9801, device='cuda:0')\n",
      "tensor(1401.2656, device='cuda:0')\n",
      "tensor(1423.7109, device='cuda:0')\n",
      "tensor(1411.1456, device='cuda:0')\n",
      "tensor(1437.7013, device='cuda:0')\n",
      "tensor(1375.1277, device='cuda:0')\n",
      "tensor(1419.3386, device='cuda:0')\n",
      "tensor(1413.9298, device='cuda:0')\n",
      "tensor(1415.4985, device='cuda:0')\n",
      "tensor(1446.5253, device='cuda:0')\n",
      "tensor(1437.7698, device='cuda:0')\n",
      "tensor(1388.5471, device='cuda:0')\n",
      "tensor(1428.6765, device='cuda:0')\n",
      "tensor(1401.9193, device='cuda:0')\n",
      "tensor(1429.9553, device='cuda:0')\n",
      "tensor(1442.7535, device='cuda:0')\n",
      "tensor(1423.3114, device='cuda:0')\n",
      "tensor(1429.2889, device='cuda:0')\n",
      "tensor(1414.3121, device='cuda:0')\n",
      "tensor(1397.8623, device='cuda:0')\n",
      "tensor(1440.3918, device='cuda:0')\n",
      "tensor(1424.1184, device='cuda:0')\n",
      "tensor(1390.7958, device='cuda:0')\n",
      "tensor(1408.7693, device='cuda:0')\n",
      "tensor(1420.5364, device='cuda:0')\n",
      "tensor(1407.0139, device='cuda:0')\n",
      "tensor(1430.4985, device='cuda:0')\n",
      "tensor(1436.0394, device='cuda:0')\n",
      "tensor(1378.6971, device='cuda:0')\n",
      "tensor(1384.6927, device='cuda:0')\n",
      "tensor(1437.6283, device='cuda:0')\n",
      "tensor(1396.1481, device='cuda:0')\n",
      "tensor(1394.1525, device='cuda:0')\n",
      "tensor(1409.0885, device='cuda:0')\n",
      "tensor(1432.5134, device='cuda:0')\n",
      "tensor(1435.1071, device='cuda:0')\n",
      "tensor(1426.2467, device='cuda:0')\n",
      "tensor(1424.2596, device='cuda:0')\n",
      "tensor(1414.3525, device='cuda:0')\n",
      "tensor(1414.4265, device='cuda:0')\n",
      "tensor(1390.7914, device='cuda:0')\n",
      "tensor(1433.2642, device='cuda:0')\n",
      "tensor(1414.9111, device='cuda:0')\n",
      "tensor(1455.5187, device='cuda:0')\n",
      "tensor(1420.4617, device='cuda:0')\n",
      "tensor(1391.0171, device='cuda:0')\n",
      "tensor(1453.9003, device='cuda:0')\n",
      "tensor(1405.9877, device='cuda:0')\n",
      "tensor(1410.1420, device='cuda:0')\n",
      "tensor(1442.2545, device='cuda:0')\n",
      "tensor(1404.9521, device='cuda:0')\n",
      "tensor(1372.6621, device='cuda:0')\n",
      "tensor(1419.3773, device='cuda:0')\n",
      "tensor(1382.9993, device='cuda:0')\n",
      "tensor(1425.6102, device='cuda:0')\n",
      "tensor(1403.5363, device='cuda:0')\n",
      "tensor(1370.0034, device='cuda:0')\n",
      "tensor(1442.6604, device='cuda:0')\n",
      "tensor(1402.6049, device='cuda:0')\n",
      "tensor(1410.5504, device='cuda:0')\n",
      "tensor(1399.4264, device='cuda:0')\n",
      "tensor(1412.2754, device='cuda:0')\n",
      "tensor(1392.4321, device='cuda:0')\n",
      "tensor(1376.1266, device='cuda:0')\n",
      "tensor(1401.9664, device='cuda:0')\n",
      "tensor(1411.7838, device='cuda:0')\n",
      "tensor(1443.9186, device='cuda:0')\n",
      "tensor(1444.6821, device='cuda:0')\n",
      "tensor(1413.4360, device='cuda:0')\n",
      "tensor(1423.8534, device='cuda:0')\n",
      "tensor(1388.7885, device='cuda:0')\n",
      "tensor(1395.0616, device='cuda:0')\n",
      "tensor(1423.4725, device='cuda:0')\n",
      "tensor(1424.9211, device='cuda:0')\n",
      "tensor(1420.6764, device='cuda:0')\n",
      "tensor(1390.1926, device='cuda:0')\n",
      "tensor(1415.8113, device='cuda:0')\n",
      "tensor(1418.0496, device='cuda:0')\n",
      "tensor(1404.3813, device='cuda:0')\n",
      "tensor(1430.0762, device='cuda:0')\n",
      "tensor(1424.5475, device='cuda:0')\n",
      "tensor(1430.5369, device='cuda:0')\n",
      "tensor(1434.0873, device='cuda:0')\n",
      "tensor(1401.9683, device='cuda:0')\n",
      "tensor(1415.3608, device='cuda:0')\n",
      "tensor(1429.3699, device='cuda:0')\n",
      "tensor(1412.6494, device='cuda:0')\n",
      "tensor(1448.6694, device='cuda:0')\n",
      "tensor(1410.6121, device='cuda:0')\n",
      "tensor(1391.7291, device='cuda:0')\n",
      "tensor(1407.3468, device='cuda:0')\n",
      "tensor(1378.2455, device='cuda:0')\n",
      "tensor(1433.6290, device='cuda:0')\n",
      "tensor(1385.8104, device='cuda:0')\n",
      "tensor(1418.0970, device='cuda:0')\n",
      "tensor(1398.1749, device='cuda:0')\n",
      "tensor(1455.0074, device='cuda:0')\n",
      "tensor(1436.0833, device='cuda:0')\n",
      "tensor(1405.1427, device='cuda:0')\n",
      "tensor(1415.4976, device='cuda:0')\n",
      "tensor(1447.0437, device='cuda:0')\n",
      "tensor(1401.4373, device='cuda:0')\n",
      "tensor(1397.7853, device='cuda:0')\n",
      "tensor(1443.7025, device='cuda:0')\n",
      "tensor(1404.0503, device='cuda:0')\n",
      "tensor(1378.5391, device='cuda:0')\n",
      "tensor(1380.1278, device='cuda:0')\n",
      "tensor(1394.7947, device='cuda:0')\n",
      "tensor(1433.6992, device='cuda:0')\n",
      "tensor(1405.1118, device='cuda:0')\n",
      "tensor(1408.2949, device='cuda:0')\n",
      "tensor(1412.9402, device='cuda:0')\n",
      "tensor(1411.6108, device='cuda:0')\n",
      "tensor(1427.9515, device='cuda:0')\n",
      "tensor(1439.8999, device='cuda:0')\n",
      "tensor(1415.5504, device='cuda:0')\n",
      "tensor(1430.5276, device='cuda:0')\n",
      "tensor(1391.2933, device='cuda:0')\n",
      "tensor(1452.3989, device='cuda:0')\n",
      "tensor(1424.3096, device='cuda:0')\n",
      "tensor(1403.3351, device='cuda:0')\n",
      "tensor(1428.5879, device='cuda:0')\n",
      "tensor(1426.1060, device='cuda:0')\n",
      "tensor(1424.6851, device='cuda:0')\n",
      "tensor(1457.1797, device='cuda:0')\n",
      "tensor(1402.0770, device='cuda:0')\n",
      "tensor(1437.6577, device='cuda:0')\n",
      "tensor(1422.1696, device='cuda:0')\n",
      "tensor(1455.9604, device='cuda:0')\n",
      "tensor(1435.0500, device='cuda:0')\n",
      "tensor(1425.2739, device='cuda:0')\n",
      "tensor(1413.8383, device='cuda:0')\n",
      "tensor(1428.0862, device='cuda:0')\n",
      "tensor(1411.9253, device='cuda:0')\n",
      "tensor(1443.0187, device='cuda:0')\n",
      "tensor(1390.1439, device='cuda:0')\n",
      "tensor(1423.5300, device='cuda:0')\n",
      "tensor(1413.5701, device='cuda:0')\n",
      "tensor(1403.7620, device='cuda:0')\n",
      "tensor(1428.0291, device='cuda:0')\n",
      "tensor(1390.6134, device='cuda:0')\n",
      "tensor(1421.0686, device='cuda:0')\n",
      "tensor(1423.3116, device='cuda:0')\n",
      "tensor(1414.9714, device='cuda:0')\n",
      "tensor(1390.1500, device='cuda:0')\n",
      "tensor(1410.1165, device='cuda:0')\n",
      "tensor(1404.7875, device='cuda:0')\n",
      "tensor(1406.3843, device='cuda:0')\n",
      "tensor(1441.6318, device='cuda:0')\n",
      "tensor(1415.9183, device='cuda:0')\n",
      "tensor(1428.1725, device='cuda:0')\n",
      "tensor(1407.1617, device='cuda:0')\n",
      "tensor(1403.5037, device='cuda:0')\n",
      "tensor(1415.5293, device='cuda:0')\n",
      "tensor(1471.3199, device='cuda:0')\n",
      "tensor(1417.6399, device='cuda:0')\n",
      "tensor(1442.4933, device='cuda:0')\n",
      "tensor(1391.2145, device='cuda:0')\n",
      "tensor(1429.0503, device='cuda:0')\n",
      "tensor(1410.3221, device='cuda:0')\n",
      "tensor(1449.4062, device='cuda:0')\n",
      "tensor(1426.3186, device='cuda:0')\n",
      "tensor(1436.4910, device='cuda:0')\n",
      "tensor(1432.6292, device='cuda:0')\n",
      "tensor(1409.1661, device='cuda:0')\n",
      "tensor(1386.2175, device='cuda:0')\n",
      "tensor(1418.7214, device='cuda:0')\n",
      "tensor(1467.4042, device='cuda:0')\n",
      "tensor(1367.8552, device='cuda:0')\n",
      "tensor(1433.6926, device='cuda:0')\n",
      "tensor(1384.7523, device='cuda:0')\n",
      "tensor(1426.1985, device='cuda:0')\n",
      "tensor(1426.8951, device='cuda:0')\n",
      "tensor(1456.9172, device='cuda:0')\n",
      "tensor(1439.2976, device='cuda:0')\n",
      "tensor(1383.0977, device='cuda:0')\n",
      "tensor(1439.6155, device='cuda:0')\n",
      "tensor(1402.3346, device='cuda:0')\n",
      "tensor(1426.3143, device='cuda:0')\n",
      "tensor(1402.8932, device='cuda:0')\n",
      "tensor(1416.5640, device='cuda:0')\n",
      "tensor(1456.1782, device='cuda:0')\n",
      "tensor(1413.2942, device='cuda:0')\n",
      "tensor(1462.2202, device='cuda:0')\n",
      "tensor(1423.3781, device='cuda:0')\n",
      "tensor(1417.4601, device='cuda:0')\n",
      "tensor(1422.1678, device='cuda:0')\n",
      "tensor(1429.6161, device='cuda:0')\n",
      "tensor(1402.4841, device='cuda:0')\n",
      "tensor(1414.9086, device='cuda:0')\n",
      "tensor(1447.2395, device='cuda:0')\n",
      "tensor(1410.5576, device='cuda:0')\n",
      "tensor(1435.1304, device='cuda:0')\n",
      "tensor(1445.4833, device='cuda:0')\n",
      "tensor(1462.0327, device='cuda:0')\n",
      "tensor(1429.1511, device='cuda:0')\n",
      "tensor(1396.9054, device='cuda:0')\n",
      "tensor(1412.2909, device='cuda:0')\n",
      "tensor(1413.7234, device='cuda:0')\n",
      "tensor(1382.2209, device='cuda:0')\n",
      "tensor(1421.2695, device='cuda:0')\n",
      "tensor(1392.6777, device='cuda:0')\n",
      "tensor(1388.9718, device='cuda:0')\n",
      "tensor(1442.7338, device='cuda:0')\n",
      "tensor(1469.9307, device='cuda:0')\n",
      "tensor(1393.4927, device='cuda:0')\n",
      "tensor(1403.5504, device='cuda:0')\n",
      "tensor(1409.3429, device='cuda:0')\n",
      "tensor(1399.5422, device='cuda:0')\n",
      "tensor(1416.5864, device='cuda:0')\n",
      "tensor(1394.3928, device='cuda:0')\n",
      "tensor(1409.7899, device='cuda:0')\n",
      "tensor(1453.8746, device='cuda:0')\n",
      "tensor(1381.0881, device='cuda:0')\n",
      "tensor(1427.6957, device='cuda:0')\n",
      "tensor(1450.8610, device='cuda:0')\n",
      "tensor(1413.1031, device='cuda:0')\n",
      "tensor(1423.2135, device='cuda:0')\n",
      "tensor(1401.2035, device='cuda:0')\n",
      "tensor(1416.9631, device='cuda:0')\n",
      "tensor(1435.2089, device='cuda:0')\n",
      "tensor(1388.0505, device='cuda:0')\n",
      "tensor(1421.7942, device='cuda:0')\n",
      "tensor(1446.2777, device='cuda:0')\n",
      "tensor(1421.6753, device='cuda:0')\n",
      "tensor(1409.7716, device='cuda:0')\n",
      "tensor(1433.9608, device='cuda:0')\n",
      "tensor(1424.1311, device='cuda:0')\n",
      "tensor(1424.4719, device='cuda:0')\n",
      "tensor(1441.1377, device='cuda:0')\n",
      "tensor(1414.9459, device='cuda:0')\n",
      "tensor(1368.2008, device='cuda:0')\n",
      "tensor(1417.5822, device='cuda:0')\n",
      "tensor(1398.5364, device='cuda:0')\n",
      "tensor(1386.3264, device='cuda:0')\n",
      "tensor(1437.7744, device='cuda:0')\n",
      "tensor(1412.7906, device='cuda:0')\n",
      "tensor(1432.3751, device='cuda:0')\n",
      "tensor(1403.2791, device='cuda:0')\n",
      "tensor(1387.6326, device='cuda:0')\n",
      "tensor(1429.4946, device='cuda:0')\n",
      "tensor(1419.7878, device='cuda:0')\n",
      "tensor(1438.6812, device='cuda:0')\n",
      "tensor(1395.1444, device='cuda:0')\n",
      "tensor(1436.9052, device='cuda:0')\n",
      "tensor(1413.0751, device='cuda:0')\n",
      "tensor(1418.9845, device='cuda:0')\n",
      "tensor(1405.2471, device='cuda:0')\n",
      "tensor(1411.0950, device='cuda:0')\n",
      "tensor(1421.9376, device='cuda:0')\n",
      "tensor(1413.3560, device='cuda:0')\n",
      "tensor(1367.5032, device='cuda:0')\n",
      "tensor(1405.0392, device='cuda:0')\n",
      "tensor(1388.7035, device='cuda:0')\n",
      "tensor(1407.5287, device='cuda:0')\n",
      "tensor(1414.1200, device='cuda:0')\n",
      "tensor(1439.0221, device='cuda:0')\n",
      "tensor(1393.5267, device='cuda:0')\n",
      "tensor(1435.9386, device='cuda:0')\n",
      "tensor(1425.6549, device='cuda:0')\n",
      "tensor(1431.9683, device='cuda:0')\n",
      "tensor(1432.4625, device='cuda:0')\n",
      "tensor(1417.9219, device='cuda:0')\n",
      "tensor(1407.6260, device='cuda:0')\n",
      "tensor(1427.5651, device='cuda:0')\n",
      "tensor(1416.0730, device='cuda:0')\n",
      "tensor(1421.1161, device='cuda:0')\n",
      "tensor(1403.8236, device='cuda:0')\n",
      "tensor(1416.0645, device='cuda:0')\n",
      "tensor(1376.7996, device='cuda:0')\n",
      "tensor(1393.6677, device='cuda:0')\n",
      "tensor(1438.7605, device='cuda:0')\n",
      "tensor(1423.3618, device='cuda:0')\n",
      "tensor(1463.4646, device='cuda:0')\n",
      "tensor(1396.2546, device='cuda:0')\n",
      "tensor(1444.3243, device='cuda:0')\n",
      "tensor(1418.8687, device='cuda:0')\n",
      "tensor(1441.7262, device='cuda:0')\n",
      "tensor(1424.7316, device='cuda:0')\n",
      "tensor(1396.1646, device='cuda:0')\n",
      "tensor(1413.4932, device='cuda:0')\n",
      "tensor(1426.1320, device='cuda:0')\n",
      "tensor(1390.5830, device='cuda:0')\n",
      "tensor(1431.2277, device='cuda:0')\n",
      "tensor(1400.0728, device='cuda:0')\n",
      "tensor(1407.7546, device='cuda:0')\n",
      "tensor(1417.7076, device='cuda:0')\n",
      "tensor(1407.9589, device='cuda:0')\n",
      "tensor(1425.9470, device='cuda:0')\n",
      "tensor(1435.1965, device='cuda:0')\n",
      "tensor(1387.6006, device='cuda:0')\n",
      "tensor(1431.1244, device='cuda:0')\n",
      "tensor(1439.4843, device='cuda:0')\n",
      "tensor(1398.0881, device='cuda:0')\n",
      "tensor(1401.8645, device='cuda:0')\n",
      "tensor(1402.4836, device='cuda:0')\n",
      "tensor(1447.8867, device='cuda:0')\n",
      "tensor(1423.4349, device='cuda:0')\n",
      "tensor(1418.9899, device='cuda:0')\n",
      "tensor(1427.9668, device='cuda:0')\n",
      "tensor(1408.2235, device='cuda:0')\n",
      "tensor(1409.9253, device='cuda:0')\n",
      "tensor(1454.1152, device='cuda:0')\n",
      "tensor(1421.9937, device='cuda:0')\n",
      "tensor(1400.3298, device='cuda:0')\n",
      "tensor(1432.9729, device='cuda:0')\n",
      "tensor(1437.8645, device='cuda:0')\n",
      "tensor(1434.7166, device='cuda:0')\n",
      "tensor(1404.5331, device='cuda:0')\n",
      "tensor(1419.6090, device='cuda:0')\n",
      "tensor(1432.2770, device='cuda:0')\n",
      "tensor(1410.4132, device='cuda:0')\n",
      "tensor(1430.6967, device='cuda:0')\n",
      "tensor(1381.2091, device='cuda:0')\n",
      "tensor(1407.2466, device='cuda:0')\n",
      "tensor(1366.9415, device='cuda:0')\n",
      "tensor(1390.4955, device='cuda:0')\n",
      "tensor(1441.1483, device='cuda:0')\n",
      "tensor(1421.5725, device='cuda:0')\n",
      "tensor(1412.2202, device='cuda:0')\n",
      "tensor(1389.6342, device='cuda:0')\n",
      "tensor(1411.2411, device='cuda:0')\n",
      "tensor(1422.3372, device='cuda:0')\n",
      "tensor(1444.0248, device='cuda:0')\n",
      "tensor(1433.1395, device='cuda:0')\n",
      "tensor(1393.9010, device='cuda:0')\n",
      "tensor(1413.8215, device='cuda:0')\n",
      "tensor(1442.7441, device='cuda:0')\n",
      "tensor(1452.9327, device='cuda:0')\n",
      "tensor(1410.1890, device='cuda:0')\n",
      "tensor(1430.2372, device='cuda:0')\n",
      "tensor(1418.0325, device='cuda:0')\n",
      "tensor(1438.3014, device='cuda:0')\n",
      "tensor(1443.3600, device='cuda:0')\n",
      "tensor(1408.1904, device='cuda:0')\n",
      "tensor(1382.3707, device='cuda:0')\n",
      "tensor(1393.3644, device='cuda:0')\n",
      "tensor(1421.3087, device='cuda:0')\n",
      "tensor(1424.9528, device='cuda:0')\n",
      "tensor(1409.1276, device='cuda:0')\n",
      "tensor(1407.3241, device='cuda:0')\n",
      "tensor(1418.3407, device='cuda:0')\n",
      "tensor(1427.1871, device='cuda:0')\n",
      "tensor(1433.0348, device='cuda:0')\n",
      "tensor(1448.2642, device='cuda:0')\n",
      "tensor(1396.0762, device='cuda:0')\n",
      "tensor(1419.9019, device='cuda:0')\n",
      "tensor(1429.7703, device='cuda:0')\n",
      "tensor(1466.7921, device='cuda:0')\n",
      "tensor(1439.5636, device='cuda:0')\n",
      "tensor(1398.9722, device='cuda:0')\n",
      "tensor(1397.6609, device='cuda:0')\n",
      "tensor(1389.4758, device='cuda:0')\n",
      "tensor(1436.4401, device='cuda:0')\n",
      "tensor(1417.3427, device='cuda:0')\n",
      "tensor(1429.1219, device='cuda:0')\n",
      "tensor(1412.8270, device='cuda:0')\n",
      "tensor(1433.6426, device='cuda:0')\n",
      "tensor(1431.3816, device='cuda:0')\n",
      "tensor(1433.6429, device='cuda:0')\n",
      "tensor(1417.9888, device='cuda:0')\n",
      "tensor(1392.1938, device='cuda:0')\n",
      "tensor(1398.5514, device='cuda:0')\n",
      "tensor(1406.0626, device='cuda:0')\n",
      "tensor(1427.8650, device='cuda:0')\n",
      "tensor(1399.3833, device='cuda:0')\n",
      "tensor(1430.3536, device='cuda:0')\n",
      "tensor(1423.5950, device='cuda:0')\n",
      "tensor(1443.1565, device='cuda:0')\n",
      "tensor(1395.7422, device='cuda:0')\n",
      "tensor(1425.0260, device='cuda:0')\n",
      "tensor(1465.7047, device='cuda:0')\n",
      "tensor(1372.0874, device='cuda:0')\n",
      "tensor(1424.3263, device='cuda:0')\n",
      "tensor(1426.6915, device='cuda:0')\n",
      "tensor(1418.3511, device='cuda:0')\n",
      "tensor(1393.4243, device='cuda:0')\n",
      "tensor(1414.2344, device='cuda:0')\n",
      "tensor(1420.3311, device='cuda:0')\n",
      "tensor(1476.8385, device='cuda:0')\n",
      "tensor(1402.8546, device='cuda:0')\n",
      "tensor(1430.8030, device='cuda:0')\n",
      "tensor(1426.7722, device='cuda:0')\n",
      "tensor(1423.0775, device='cuda:0')\n",
      "tensor(1422.2107, device='cuda:0')\n",
      "tensor(1444.3984, device='cuda:0')\n",
      "tensor(1425.5894, device='cuda:0')\n",
      "tensor(1431.3579, device='cuda:0')\n",
      "tensor(1422.7729, device='cuda:0')\n",
      "tensor(1417.5756, device='cuda:0')\n",
      "tensor(1450.4500, device='cuda:0')\n",
      "tensor(1406.1389, device='cuda:0')\n",
      "tensor(1418.3615, device='cuda:0')\n",
      "tensor(1416.9739, device='cuda:0')\n",
      "tensor(1411.9868, device='cuda:0')\n",
      "tensor(1425.8538, device='cuda:0')\n",
      "tensor(1426.1919, device='cuda:0')\n",
      "tensor(1426.7339, device='cuda:0')\n",
      "tensor(1453.3602, device='cuda:0')\n",
      "tensor(1412.1228, device='cuda:0')\n",
      "tensor(1434.7325, device='cuda:0')\n",
      "tensor(1429.0167, device='cuda:0')\n",
      "tensor(1395.7434, device='cuda:0')\n",
      "tensor(1378.9285, device='cuda:0')\n",
      "tensor(1425.6672, device='cuda:0')\n",
      "tensor(1414.3475, device='cuda:0')\n",
      "tensor(1371.6141, device='cuda:0')\n",
      "tensor(1401.0164, device='cuda:0')\n",
      "tensor(1409.3240, device='cuda:0')\n",
      "tensor(1435.7933, device='cuda:0')\n",
      "tensor(1436.4623, device='cuda:0')\n",
      "tensor(1420.3639, device='cuda:0')\n",
      "tensor(1409.8463, device='cuda:0')\n",
      "tensor(1432.6927, device='cuda:0')\n",
      "tensor(1407.5461, device='cuda:0')\n",
      "tensor(1443.7665, device='cuda:0')\n",
      "tensor(1409.5470, device='cuda:0')\n",
      "tensor(1424.9325, device='cuda:0')\n",
      "tensor(1404.4135, device='cuda:0')\n",
      "tensor(1393.4047, device='cuda:0')\n",
      "tensor(1422.9547, device='cuda:0')\n",
      "tensor(1415.2618, device='cuda:0')\n",
      "tensor(1434.4104, device='cuda:0')\n",
      "tensor(1435.8473, device='cuda:0')\n",
      "tensor(1403.9790, device='cuda:0')\n",
      "tensor(1404.5652, device='cuda:0')\n",
      "tensor(1399.2827, device='cuda:0')\n",
      "tensor(1406.3085, device='cuda:0')\n",
      "tensor(1430.8840, device='cuda:0')\n",
      "tensor(1434.7399, device='cuda:0')\n",
      "tensor(1458.6427, device='cuda:0')\n",
      "tensor(1394.4055, device='cuda:0')\n",
      "tensor(1455.5294, device='cuda:0')\n",
      "tensor(1413.3123, device='cuda:0')\n",
      "tensor(1423.0087, device='cuda:0')\n",
      "tensor(1440.9586, device='cuda:0')\n",
      "tensor(1442.8912, device='cuda:0')\n",
      "tensor(1412.0784, device='cuda:0')\n",
      "tensor(1364.8770, device='cuda:0')\n",
      "tensor(1441.4070, device='cuda:0')\n",
      "tensor(1433.6018, device='cuda:0')\n",
      "tensor(1414.3236, device='cuda:0')\n",
      "tensor(1433.8555, device='cuda:0')\n",
      "tensor(1389.8689, device='cuda:0')\n",
      "tensor(1425.4111, device='cuda:0')\n",
      "tensor(1417.5470, device='cuda:0')\n",
      "tensor(1428.3523, device='cuda:0')\n",
      "tensor(1398.0112, device='cuda:0')\n",
      "tensor(1437.1348, device='cuda:0')\n",
      "tensor(1393.8981, device='cuda:0')\n",
      "tensor(1407.0286, device='cuda:0')\n",
      "tensor(1400.5671, device='cuda:0')\n",
      "tensor(1437.9875, device='cuda:0')\n",
      "tensor(1452.1531, device='cuda:0')\n",
      "tensor(1438.9786, device='cuda:0')\n",
      "tensor(1410.6361, device='cuda:0')\n",
      "tensor(1437.1208, device='cuda:0')\n",
      "tensor(1407.1720, device='cuda:0')\n",
      "tensor(1440.0734, device='cuda:0')\n",
      "tensor(1424.1060, device='cuda:0')\n",
      "tensor(1382.5692, device='cuda:0')\n",
      "tensor(1435.6165, device='cuda:0')\n",
      "tensor(1425.2683, device='cuda:0')\n",
      "tensor(1403.9303, device='cuda:0')\n",
      "tensor(1424.5748, device='cuda:0')\n",
      "tensor(1460.4961, device='cuda:0')\n",
      "tensor(1443.0353, device='cuda:0')\n",
      "tensor(1403.3746, device='cuda:0')\n",
      "tensor(1444.2716, device='cuda:0')\n",
      "tensor(1426.3756, device='cuda:0')\n",
      "tensor(1457.4364, device='cuda:0')\n",
      "tensor(1379.8646, device='cuda:0')\n",
      "tensor(1402.8904, device='cuda:0')\n",
      "tensor(1418.7998, device='cuda:0')\n",
      "tensor(1380.7080, device='cuda:0')\n",
      "tensor(1432.6666, device='cuda:0')\n",
      "tensor(1432.7186, device='cuda:0')\n",
      "tensor(1410.2253, device='cuda:0')\n",
      "tensor(1396.5129, device='cuda:0')\n",
      "tensor(1403.6827, device='cuda:0')\n",
      "tensor(1397.1885, device='cuda:0')\n",
      "tensor(1417.3263, device='cuda:0')\n",
      "tensor(1424.6915, device='cuda:0')\n",
      "tensor(1396.1759, device='cuda:0')\n",
      "tensor(1419.0554, device='cuda:0')\n",
      "tensor(1429.3740, device='cuda:0')\n",
      "tensor(1433.6788, device='cuda:0')\n",
      "tensor(1416.2358, device='cuda:0')\n",
      "tensor(1461.6334, device='cuda:0')\n",
      "tensor(1411.6815, device='cuda:0')\n",
      "tensor(1390.0250, device='cuda:0')\n",
      "tensor(1397.8743, device='cuda:0')\n",
      "tensor(1442.3610, device='cuda:0')\n",
      "tensor(1424.1720, device='cuda:0')\n",
      "tensor(1395.1184, device='cuda:0')\n",
      "tensor(1421.2360, device='cuda:0')\n",
      "tensor(1419.8759, device='cuda:0')\n",
      "tensor(1428.9984, device='cuda:0')\n",
      "tensor(1408.3887, device='cuda:0')\n",
      "tensor(1435.8839, device='cuda:0')\n",
      "tensor(1411.4194, device='cuda:0')\n",
      "tensor(1403.6741, device='cuda:0')\n",
      "tensor(1406.7604, device='cuda:0')\n",
      "tensor(1432.6162, device='cuda:0')\n",
      "tensor(1425.4380, device='cuda:0')\n",
      "tensor(1432.6206, device='cuda:0')\n",
      "tensor(1419.0830, device='cuda:0')\n",
      "tensor(1396.7922, device='cuda:0')\n",
      "tensor(1461.4384, device='cuda:0')\n",
      "tensor(1405.5444, device='cuda:0')\n",
      "tensor(1418.2954, device='cuda:0')\n",
      "tensor(1410.6268, device='cuda:0')\n",
      "tensor(1429.5880, device='cuda:0')\n",
      "tensor(1390.5955, device='cuda:0')\n",
      "tensor(1449.7338, device='cuda:0')\n",
      "tensor(1427.1417, device='cuda:0')\n",
      "tensor(1393.3341, device='cuda:0')\n",
      "tensor(1446.5208, device='cuda:0')\n",
      "tensor(1427.9879, device='cuda:0')\n",
      "tensor(1430.5674, device='cuda:0')\n",
      "tensor(1419.5295, device='cuda:0')\n",
      "tensor(1396.2969, device='cuda:0')\n",
      "tensor(1406.3234, device='cuda:0')\n",
      "tensor(1388.9407, device='cuda:0')\n",
      "tensor(1410.9679, device='cuda:0')\n",
      "tensor(1405.6943, device='cuda:0')\n",
      "tensor(1441.3717, device='cuda:0')\n",
      "tensor(1413.4684, device='cuda:0')\n",
      "tensor(1414.8881, device='cuda:0')\n",
      "tensor(1430.7401, device='cuda:0')\n",
      "tensor(1442.6456, device='cuda:0')\n",
      "tensor(1403.2085, device='cuda:0')\n",
      "tensor(1417.8706, device='cuda:0')\n",
      "tensor(1407.8134, device='cuda:0')\n",
      "tensor(1412.7100, device='cuda:0')\n",
      "tensor(1412.6792, device='cuda:0')\n",
      "tensor(1388.2871, device='cuda:0')\n",
      "tensor(1399.6310, device='cuda:0')\n",
      "tensor(1385.9854, device='cuda:0')\n",
      "tensor(1397.1167, device='cuda:0')\n",
      "tensor(1409.9941, device='cuda:0')\n",
      "tensor(1427.4344, device='cuda:0')\n",
      "tensor(1420.9352, device='cuda:0')\n",
      "tensor(1437.5387, device='cuda:0')\n",
      "tensor(1420.9938, device='cuda:0')\n",
      "tensor(1435.9974, device='cuda:0')\n",
      "tensor(1461.9924, device='cuda:0')\n",
      "tensor(1382.0372, device='cuda:0')\n",
      "tensor(1445.2047, device='cuda:0')\n",
      "tensor(1414.5450, device='cuda:0')\n",
      "tensor(1385.1598, device='cuda:0')\n",
      "tensor(1409.8971, device='cuda:0')\n",
      "tensor(1360.6919, device='cuda:0')\n",
      "tensor(1445.5201, device='cuda:0')\n",
      "tensor(1449.6940, device='cuda:0')\n",
      "tensor(1403.6687, device='cuda:0')\n",
      "tensor(1423.0311, device='cuda:0')\n",
      "tensor(1432.3330, device='cuda:0')\n",
      "tensor(1417.0438, device='cuda:0')\n",
      "tensor(1410.4779, device='cuda:0')\n",
      "tensor(1415.6406, device='cuda:0')\n",
      "tensor(1420.9569, device='cuda:0')\n",
      "tensor(1404.5955, device='cuda:0')\n",
      "tensor(1463.2822, device='cuda:0')\n",
      "tensor(1394.4556, device='cuda:0')\n",
      "tensor(1424.5873, device='cuda:0')\n",
      "tensor(1463.4976, device='cuda:0')\n",
      "tensor(1432.5387, device='cuda:0')\n",
      "tensor(1409.5015, device='cuda:0')\n",
      "tensor(1416.9995, device='cuda:0')\n",
      "tensor(1419.6348, device='cuda:0')\n",
      "tensor(1443.1252, device='cuda:0')\n",
      "tensor(1418.1210, device='cuda:0')\n",
      "tensor(1367.6191, device='cuda:0')\n",
      "tensor(1425.0654, device='cuda:0')\n",
      "tensor(1400.9357, device='cuda:0')\n",
      "tensor(1435.8877, device='cuda:0')\n",
      "tensor(1406.3204, device='cuda:0')\n",
      "tensor(1452.8177, device='cuda:0')\n",
      "tensor(1402.5817, device='cuda:0')\n",
      "tensor(1431.4229, device='cuda:0')\n",
      "tensor(1441.7743, device='cuda:0')\n",
      "tensor(1435.2402, device='cuda:0')\n",
      "tensor(1422.8839, device='cuda:0')\n",
      "tensor(1379.6204, device='cuda:0')\n",
      "Time taken: 0.821382999420166\n",
      "实验一消耗时间：0.04613924026489258，实验二消耗时间：0.821382999420166\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 生成随机矩阵\n",
    "matrices = [torch.randn(100, 100).to(device) for i in range(1000)]\n",
    "\n",
    "# 实验一：计算时间\n",
    "start_time_1 = time.time()\n",
    "for i in range(1000):\n",
    "    result = torch.mm(matrices[i], matrices[i].t())\n",
    "    frobenius_norm = torch.norm(result)\n",
    "\n",
    "end_time_1 = time.time()\n",
    "print(\"Time taken:\", end_time_1 - start_time_1)\n",
    "\n",
    "# 实验二：计算时间\n",
    "start_time_2 = time.time()\n",
    "for i in range(1000):\n",
    "    result = torch.mm(matrices[i], matrices[i].t())\n",
    "    frobenius_norm = torch.norm(result)\n",
    "    print(frobenius_norm)\n",
    "\n",
    "end_time_2 = time.time()\n",
    "print(\"Time taken:\", end_time_2 - start_time_2)\n",
    "\n",
    "print(f'实验一消耗时间：{end_time_1 - start_time_1}，实验二消耗时间：{end_time_2 - start_time_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c2cafb-ec4f-406d-ae2c-222d3f35e88f",
   "metadata": {},
   "source": [
    "### 练习四\n",
    "\n",
    "4. 测量同时在两个GPU上执行两个矩阵乘法与在一个GPU上按顺序执行两个矩阵乘法所需的时间。提示：应该看到近乎线性的缩放。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1f034f-e69d-4395-90c1-ee76e4db65cc",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1c9d2-130c-4cac-b64c-98ef74351178",
   "metadata": {},
   "source": [
    "&emsp;&emsp;执行两个矩阵乘法并行在两个GPU上所需的时间通常会比在单个GPU上按顺序执行这两个操作要快得多。但实际的时间取决于矩阵的大小、硬件配置和算法实现。\n",
    "\n",
    "&emsp;&emsp;但由于笔者只有一张卡，所以只做了在单个GPU上顺序执行两个矩阵乘法的实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdf7a8b8-ef25-486d-8afe-85f18852a25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential time: 0.00534868 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# 创建两个随机矩阵\n",
    "a = torch.randn(10000, 10000).cuda()\n",
    "b = torch.randn(10000, 10000).cuda()\n",
    "\n",
    "# 顺序执行\n",
    "start_time = time.time()\n",
    "c1 = torch.matmul(a, b)\n",
    "c2 = torch.matmul(a, b)\n",
    "end_time = time.time()\n",
    "sequential_time = end_time - start_time\n",
    "\n",
    "print(f\"Sequential time: {sequential_time:.8f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b5a014-1aba-4bdc-918f-88ad858749c4",
   "metadata": {},
   "source": [
    "[torch.mm和torch.matmul的区别](https://blog.csdn.net/qq_35091353/article/details/117234223)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
