{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70624503-5e7d-4593-8158-d3f8cc199801",
   "metadata": {},
   "source": [
    "# 从全连接层到卷积\n",
    "\n",
    "我们之前讨论的多层感知机十分适合处理表格数据，其中行对应样本，列对应特征。\n",
    "对于表格数据，我们寻找的模式可能涉及特征之间的交互，**但是我们不能预先假设任何与特征交互相关的先验结构。**\n",
    "此时，多层感知机可能是最好的选择，然而对于高维感知数据，这种缺少结构的网络可能会变得不实用。\n",
    "\n",
    "例如，在之前猫狗分类的例子中：假设我们有一个足够充分的照片数据集，数据集中是拥有标注的照片，每张照片具有百万级像素，这意味着网络的每次输入都有一百万个维度。\n",
    "即使将隐藏层维度降低到1000，这个全连接层也将有$10^6 \\times 10^3 = 10^9$个参数。\n",
    "想要训练这个模型将不可实现，因为需要有大量的GPU、分布式优化训练的经验和超乎常人的耐心。\n",
    "\n",
    "有些读者可能会反对这个观点，认为要求百万像素的分辨率可能不是必要的。\n",
    "然而，即使分辨率减小为十万像素，使用1000个隐藏单元的隐藏层也可能不足以学习到良好的图像特征，在真实的系统中我们仍然需要数十亿个参数。\n",
    "此外，拟合如此多的参数还需要收集大量的数据。\n",
    "然而，如今人类和机器都能很好地区分猫和狗：这是因为图像中本就拥有丰富的结构，而这些结构可以被人类和机器学习模型使用。\n",
    "*卷积神经网络*（convolutional neural networks，CNN）是机器学习利用自然图像中一些已知结构的创造性方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a7e2d-1d94-41b6-9c0e-337f37aab0a9",
   "metadata": {},
   "source": [
    "## 不变性\n",
    "\n",
    "想象一下，假设我们想从一张图片中找到某个物体。\n",
    "合理的假设是：无论哪种方法找到这个物体，都应该和物体的位置无关。\n",
    "理想情况下，我们的系统应该能够利用常识：猪通常不在天上飞，飞机通常不在水里游泳。\n",
    "但是，如果一只猪出现在图片顶部，我们还是应该认出它。\n",
    "我们可以从儿童游戏”沃尔多在哪里”（如下图所示）中得到灵感：\n",
    "在这个游戏中包含了许多充斥着活动的混乱场景，而沃尔多通常潜伏在一些不太可能的位置，读者的目标就是找出他。\n",
    "尽管沃尔多的装扮很有特点，但是在眼花缭乱的场景中找到他也如大海捞针。\n",
    "然而沃尔多的样子并不取决于他潜藏的地方，因此我们可以使用一个“沃尔多检测器”扫描图像。\n",
    "该检测器将图像分割成多个区域，并为每个区域包含沃尔多的可能性打分。\n",
    "卷积神经网络正是将*空间不变性*（spatial invariance）的这一概念系统化，从而基于这个模型使用较少的参数来学习有用的表示。\n",
    "\n",
    "![沃尔多游戏示例图。](../assets/where-wally-walker-books.jpg)\n",
    "\n",
    "现在，我们将上述想法总结一下，从而帮助我们设计适合于计算机视觉的神经网络架构。\n",
    "\n",
    "1. *平移不变性*（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。\n",
    "1. *局部性*（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。\n",
    "\n",
    "让我们看看这些原则是如何转化为数学表示的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b600a-82f3-4d60-906e-91ba438292cb",
   "metadata": {},
   "source": [
    "## 多层感知机的限制\n",
    "\n",
    "首先，多层感知机的输入是二维图像$\\mathbf{X}$，其隐藏表示$\\mathbf{H}$在数学上是一个矩阵，在代码中表示为二维张量。\n",
    "其中$\\mathbf{X}$和$\\mathbf{H}$具有相同的形状。\n",
    "为了方便理解，我们可以认为，无论是输入还是隐藏表示都拥有空间结构。\n",
    "\n",
    "使用$[\\mathbf{X}]_{i, j}$和$[\\mathbf{H}]_{i, j}$分别表示输入图像和隐藏表示中位置（$i$,$j$）处的像素。\n",
    "为了使每个隐藏神经元都能接收到每个输入像素的信息，我们将参数从权重矩阵（如同我们先前在多层感知机中所做的那样）替换为四阶权重张量$\\mathsf{W}$。假设$\\mathbf{U}$包含偏置参数，我们可以将全连接层形式化地表示为\n",
    "\n",
    "$$\\begin{aligned} \\left[\\mathbf{H}\\right]_{i, j} &= [\\mathbf{U}]_{i, j} + \\sum_k \\sum_l[\\mathsf{W}]_{i, j, k, l}  [\\mathbf{X}]_{k, l}\\\\ &=  [\\mathbf{U}]_{i, j} +\n",
    "\\sum_a \\sum_b [\\mathsf{V}]_{i, j, a, b}  [\\mathbf{X}]_{i+a, j+b}.\\end{aligned}$$\n",
    "\n",
    "其中，从$\\mathsf{W}$到$\\mathsf{V}$的转换只是形式上的转换，因为在这两个四阶张量的元素之间存在一一对应的关系。\n",
    "我们只需重新索引下标$(k, l)$，使$k = i+a$、$l = j+b$，由此可得$[\\mathsf{V}]_{i, j, a, b} = [\\mathsf{W}]_{i, j, i+a, j+b}$。\n",
    "索引$a$和$b$通过在正偏移和负偏移之间移动覆盖了整个图像。\n",
    "对于隐藏表示中任意给定位置（$i$,$j$）处的像素值$[\\mathbf{H}]_{i, j}$，可以通过在$x$中以$(i, j)$为中心对像素进行加权求和得到，加权使用的权重为$[\\mathsf{V}]_{i, j, a, b}$。\n",
    "\n",
    "[四阶权重张量W是什么？](https://kimi.moonshot.cn/share/cqschupmqu07lj3c7kjg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00304e3e-bf6d-4b30-8ddb-7442ebeb3c4b",
   "metadata": {},
   "source": [
    "### 平移不变性\n",
    "\n",
    "现在引用上述的第一个原则：平移不变性。\n",
    "这意味着检测对象在输入$\\mathbf{X}$中的平移，应该仅导致隐藏表示$\\mathbf{H}$中的平移。也就是说，$\\mathsf{V}$和$\\mathbf{U}$实际上不依赖于$(i, j)$的值，即$[\\mathsf{V}]_{i, j, a, b} = [\\mathbf{V}]_{a, b}$。并且$\\mathbf{U}$是一个常数，比如$u$。因此，我们可以简化$\\mathbf{H}$定义为：\n",
    "\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_a\\sum_b [\\mathbf{V}]_{a, b} [\\mathbf{X}]_{i+a, j+b}.$$\n",
    "\n",
    "这就是*卷积*（convolution）。我们是在使用系数$[\\mathbf{V}]_{a, b}$对位置$(i, j)$附近的像素$(i+a, j+b)$进行加权得到$[\\mathbf{H}]_{i, j}$。\n",
    "注意，$[\\mathbf{V}]_{a, b}$的系数比$[\\mathsf{V}]_{i, j, a, b}$少很多，因为前者不再依赖于图像中的位置。这就是显著的进步！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a6fc6-fc69-42a3-9240-8413a89ce7ad",
   "metadata": {},
   "source": [
    "### 局部性\n",
    "\n",
    "现在引用上述的第二个原则：局部性。如上所述，为了收集用来训练参数$[\\mathbf{H}]_{i, j}$的相关信息，我们不应偏离到距$(i, j)$很远的地方。这意味着在$|a|> \\Delta$或$|b| > \\Delta$的范围之外，我们可以设置$[\\mathbf{V}]_{a, b} = 0$。因此，我们可以将$[\\mathbf{H}]_{i, j}$重写为\n",
    "\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}.$$\n",
    ":eqlabel:`eq_conv-layer`\n",
    "\n",
    "简而言之， :eqlabel:`eq_conv-layer`是一个*卷积层*（convolutional layer），而卷积神经网络是包含卷积层的一类特殊的神经网络。\n",
    "在深度学习研究社区中，$\\mathbf{V}$被称为*卷积核*（convolution kernel）或者*滤波器*（filter），亦或简单地称之为该卷积层的*权重*，通常该权重是可学习的参数。\n",
    "当图像处理的局部区域很小时，卷积神经网络与多层感知机的训练差异可能是巨大的：以前，多层感知机可能需要数十亿个参数来表示网络中的一层，而现在卷积神经网络通常只需要几百个参数，而且不需要改变输入或隐藏表示的维数。\n",
    "参数大幅减少的代价是，我们的特征现在是平移不变的，并且当确定每个隐藏活性值时，每一层只包含局部的信息。\n",
    "以上所有的权重学习都将依赖于归纳偏置。当这种偏置与现实相符时，我们就能得到样本有效的模型，并且这些模型能很好地泛化到未知数据中。\n",
    "但如果这偏置与现实不符时，比如当图像不满足平移不变时，我们的模型可能难以拟合我们的训练数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94732be-7622-4677-a86f-fcefe7899838",
   "metadata": {},
   "source": [
    "## 卷积\n",
    "\n",
    "在进一步讨论之前，我们先简要回顾一下为什么上面的操作被称为卷积。在数学中，两个函数（比如$f, g: \\mathbb{R}^d \\to \\mathbb{R}$）之间的“卷积”被定义为\n",
    "\n",
    "$$(f * g)(\\mathbf{x}) = \\int f(\\mathbf{z}) g(\\mathbf{x}-\\mathbf{z}) d\\mathbf{z}.$$\n",
    "\n",
    "也就是说，卷积是当把一个函数“翻转”并移位$\\mathbf{x}$时，测量$f$和$g$之间的重叠。\n",
    "当为离散对象时，积分就变成求和。例如，对于由索引为$\\mathbb{Z}$的、平方可和的、无限维向量集合中抽取的向量，我们得到以下定义：\n",
    "\n",
    "$$(f * g)(i) = \\sum_a f(a) g(i-a).$$\n",
    "\n",
    "对于二维张量，则为$f$的索引$(a, b)$和$g$的索引$(i-a, j-b)$上的对应加和：\n",
    "\n",
    "$$(f * g)(i, j) = \\sum_a\\sum_b f(a, b) g(i-a, j-b).$$\n",
    ":eqlabel:`eq_2d-conv-discrete`\n",
    "\n",
    "这看起来类似于 :eqref:`eq_conv-layer`，但有一个主要区别：这里不是使用$(i+a, j+b)$，而是使用差值。然而，这种区别是表面的，因为我们总是可以匹配 :eqref:`eq_conv-layer`和 :eqref:`eq_2d-conv-discrete`之间的符号。我们在 :eqref:`eq_conv-layer`中的原始定义更正确地描述了*互相关*（cross-correlation），这个问题将在下一节中讨论。\n",
    "\n",
    "[卷积数学概念](https://blog.csdn.net/poisonchry/article/details/114535427)\n",
    "\n",
    "[卷积的通俗理解](https://www.zhihu.com/question/22298352)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afadf4fd-dd98-4c13-9989-4d38461694ad",
   "metadata": {},
   "source": [
    "## “沃尔多在哪里”回顾\n",
    "\n",
    "回到上面的“沃尔多在哪里”游戏，让我们看看它到底是什么样子。卷积层根据滤波器$\\mathbf{V}$选取给定大小的窗口，并加权处理图片，如下图中所示。我们的目标是学习一个模型，以便探测出在“沃尔多”最可能出现的地方。\n",
    "\n",
    "![发现沃尔多。](../assets/waldo-mask.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dd63b9-3eb9-42f1-a5cb-80cb29936cc4",
   "metadata": {},
   "source": [
    "### 通道\n",
    "\n",
    "然而这种方法有一个问题：我们忽略了图像一般包含三个通道/三种原色（红色、绿色和蓝色）。\n",
    "实际上，图像不是二维张量，而是一个由高度、宽度和颜色组成的三维张量，比如包含$1024 \\times 1024 \\times 3$个像素。\n",
    "前两个轴与像素的空间位置有关，而第三个轴可以看作每个像素的多维表示。\n",
    "因此，我们将$\\mathsf{X}$索引为$[\\mathsf{X}]_{i, j, k}$。由此卷积相应地调整为$[\\mathsf{V}]_{a,b,c}$，而不是$[\\mathbf{V}]_{a,b}$。\n",
    "\n",
    "此外，由于输入图像是三维的，我们的隐藏表示$\\mathsf{H}$也最好采用三维张量。\n",
    "换句话说，对于每一个空间位置，我们想要采用一组而不是一个隐藏表示。这样一组隐藏表示可以想象成一些互相堆叠的二维网格。\n",
    "因此，我们可以把隐藏表示想象为一系列具有二维张量的*通道*（channel）。\n",
    "这些通道有时也被称为*特征映射*（feature maps），因为每个通道都向后续层提供一组空间化的学习特征。\n",
    "**直观上可以想象在靠近输入的底层，一些通道专门识别边缘，而一些通道专门识别纹理。**\n",
    "\n",
    "为了支持输入$\\mathsf{X}$和隐藏表示$\\mathsf{H}$中的多个通道，我们可以在$\\mathsf{V}$中添加第四个坐标，即$[\\mathsf{V}]_{a, b, c, d}$。综上所述，\n",
    "\n",
    "$$[\\mathsf{H}]_{i,j,d} = \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} \\sum_c [\\mathsf{V}]_{a, b, c, d} [\\mathsf{X}]_{i+a, j+b, c},$$\n",
    ":eqlabel:`eq_conv-layer-channels`\n",
    "\n",
    "其中隐藏表示$\\mathsf{H}$中的索引$d$表示输出通道，而随后的输出将继续以三维张量$\\mathsf{H}$作为输入进入下一个卷积层。\n",
    "所以， :eqref:`eq_conv-layer-channels`可以定义具有多个通道的卷积层，而其中$\\mathsf{V}$是该卷积层的权重。\n",
    "\n",
    "然而，仍有许多问题亟待解决。\n",
    "例如，图像中是否到处都有存在沃尔多的可能？如何有效地计算输出层？如何选择适当的激活函数？为了训练有效的网络，如何做出合理的网络设计选择？我们将在本章的其它部分讨论这些问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f577300-8dfe-4124-9a94-bf2b0719947e",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "- 图像的平移不变性使我们以相同的方式处理局部图像，而不在乎它的位置。\n",
    "- 局部性意味着计算相应的隐藏表示只需一小部分局部图像像素。\n",
    "- 在图像处理中，卷积层通常比全连接层需要更少的参数，但依旧获得高效用的模型。\n",
    "- 卷积神经网络（CNN）是一类特殊的神经网络，它可以包含多个卷积层。\n",
    "- 多个输入和输出通道使模型在每个空间位置可以获取图像的多方面特征。\n",
    "- 卷积是一种运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3e5c4-f642-4a38-b31c-3164ae15a981",
   "metadata": {},
   "source": [
    "## 练习\n",
    "\n",
    "1. 假设卷积层 :eqref:`eq_conv-layer`覆盖的局部区域$\\Delta = 0$。在这种情况下，证明卷积内核为每组通道独立地实现一个全连接层。\n",
    "1. 为什么平移不变性可能也不是好主意呢？\n",
    "1. 当从图像边界像素获取隐藏表示时，我们需要思考哪些问题？\n",
    "1. 描述一个类似的音频卷积层的架构。\n",
    "1. 卷积层也适合于文本数据吗？为什么？\n",
    "1. 证明在 :eqref:`eq_2d-conv-discrete`中，$f * g = g * f$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfabcd2-2afd-4eeb-b801-9067122a8854",
   "metadata": {},
   "source": [
    "### 练习一\n",
    "\n",
    "1. 假设卷积层 :eqref:`eq_conv-layer`覆盖的局部区域$\\Delta = 0$。在这种情况下，证明卷积内核为每组通道独立地实现一个全连接层。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca0da0-aeca-488a-9455-2d94baac8d22",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9c2b3-5db1-44e3-ba1b-ed1daac689ee",
   "metadata": {},
   "source": [
    "&emsp;&emsp;局部区域 $\\Delta=0$ 表示卷积核的大小等于输入的大小。实际就是问，$1×1$ 的卷积核是否等价于全连接（参见本书，`NiN`网络结构）。因此，每个卷积核只能覆盖一个像素点，在这种情况下，卷积层的计算方式与全连接层非常相似。因为每个卷积核只能看到看到一个通道的信息，相当于每个卷积核只是一个全连接层的权重矩阵。所以，卷积内核可以看作是每组通道独立地实现一个全连接层。每个卷积核都有自己的权重，每个输入通道都被独立处理，输出通道是各个输入通道的加权和。这种独立处理的方式有效地减少了权重的数量，从而降低了计算成本，并且能够提取出输入数据中的空间特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f7dfb8-467f-43ac-8de9-3ae5deb0d491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2159,  0.2156,  0.1076, -0.4275,  0.3792],\n",
      "        [-0.0912,  0.3283,  0.7278, -0.4956, -0.1462]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2159,  0.2156,  0.1076, -0.4275,  0.3792],\n",
      "        [-0.0912,  0.3283,  0.7278, -0.4956, -0.1462]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 代码验证\n",
    "# 导入PyTorch库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个神经网络类MyNet1，继承自nn.Module\n",
    "class MyNet1(nn.Module):\n",
    "    def __init__(self, linear1, linear2):\n",
    "        super(MyNet1, self).__init__()\n",
    "        # 初始化两个线性层\n",
    "        self.linear1 = linear1\n",
    "        self.linear2 = linear2\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 定义前向传播过程：向展平输入X，然后通过两个线性层\n",
    "        return self.linear2(self.linear1(nn.Flatten()(X)))\n",
    "\n",
    "# 定义另一个神经网络类MyNet2，也继承自nn.Module\n",
    "class MyNet2(nn.Module):\n",
    "    def __init__(self, linear, conv2d):\n",
    "        super(MyNet2, self).__init__()\n",
    "        # 初始化一个线性层和卷积层\n",
    "        self.linear = linear\n",
    "        self.conv2d = conv2d\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 定义前向传播过程\n",
    "        X = self.linear(nn.Flatten()(X)) # 先展平输入X，然后通过线性层\n",
    "        X = X.reshape(X.shape[0], -1, 1, 1) # 调整X的形状以适应卷积层的输入\n",
    "        X = nn.Flatten()(self.conv2d(X)) # 通过卷积层，然后再次展开\n",
    "        return X\n",
    "\n",
    "# 初始化线性层和卷积层\n",
    "linear1 = nn.Linear(15, 10) # 创建一个线性层，输入特征数为15，输出特征数为10\n",
    "linear2 = nn.Linear(10, 5) # 创建另一个线性层，输入特征数为10，输出特征数为5\n",
    "conv2d = nn.Conv2d(10, 5, 1) # 创建一个卷积层，输入通道数为10，输出通道数为5，卷积核大小为1x1\n",
    "\n",
    "# 将卷积层的权重和偏置参数重塑并分别赋值给linear2的权重和偏置\n",
    "linear2.weight = nn.Parameter(conv2d.weight.reshape(linear2.weight.shape))  # 重塑卷积层的权重并赋值给linear2的权重\n",
    "linear2.bias = nn.Parameter(conv2d.bias) # 赋值卷积层的偏置参数给linear2的偏置参数\n",
    "\n",
    "# 实例化两个网络\n",
    "net1 = MyNet1(linear1, linear2) # 创建net1，将linear1和linear2作为参数传递\n",
    "net2 = MyNet2(linear1, conv2d) # 创建net2，将linear1和conv2d作为参数传递\n",
    "\n",
    "# 创建一个随机输入张量X，形状为(2, 3, 5)\n",
    "X = torch.randn(2, 3, 5)\n",
    "\n",
    "# 打印两个网络对同一输入X的输出结果\n",
    "# 两个结果实际存在一定的误差，直接print(net1(x) == net2(X))得到的结果不全是True\n",
    "print(net1(X)) # 使用net1进行前向传播并打印结果\n",
    "print(net2(X)) # 使用net2进行前向传播并打印结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e16423e-d43d-4c4b-9b92-64de635a6d2a",
   "metadata": {},
   "source": [
    "**结论：** $1×1$ 的卷积核等价于全连接。使用$1×1$的卷积核输入层和隐藏层之间的参数量和直接使用多层感知机的参数量是一样的。\n",
    "\n",
    "[全连接层的原理详细解读](https://blog.csdn.net/m0_71212744/article/details/141329609)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adacc566-94bd-4b13-b9cb-a64914669388",
   "metadata": {},
   "source": [
    "### 练习二\n",
    "\n",
    "2. 为什么平移不变性可能也不是好主意呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2a2bc7-4661-4d68-bc5e-ad50b733c2ac",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36788867-d07b-4ab7-8b04-b1468c122fdf",
   "metadata": {},
   "source": [
    "&emsp;&emsp;平移不变性是一种在信号处理和图像分析中常见的特性，尤其是在卷积神经网络(`CNNs`)中。它意味着一个系统或函数对输入数据的平移是不变的，即如果输入数据发生平移，输出不会改变。这对于很多应用来说是有益的，比如在图像识别中，无论物体在图像中的位置如何，模型都能识别它。\\\n",
    "&emsp;&emsp;平移不变性可能也存在一些局限性或不足之处：\\\n",
    "&emsp;&emsp;1.**丢失空间信息**：当模型对位置不敏感时，它可能无法识别对象的确切位置或对象之间的空间关系。在某些任务中，如场景理解或对象定位，这种空间信息非常重要。\\\n",
    "&emsp;&emsp;2.**不适用于所有任务**：对于一些特定的任务，如图像中文本的识别或布局分析，平移不变性可能不是一个理想的特性，因为这些任务需要对位置和排列非常敏感。\\\n",
    "&emsp;&emsp;3.**过度泛化**：平移不变性可能导致模型过度泛化，无法识别某些应该被视为不同的模式或对象。例如，在医学成像分析中，肿瘤的确切位置对于诊断至关重要。\\\n",
    "&emsp;&emsp;4.**缩放和旋转问题**：虽然平移不变性处理位置的变化，但它不处理缩放或旋转，这可能是图像识别中的关键因素。\\\n",
    "&emsp;&emsp;5.**计算效率**：为了实现平移不变性，卷积网络通常需要更多的参数和计算资源，这可能导致效率低下，尤其是在资源受限的环境中。\\\n",
    "&emsp;&emsp;6.**局部性限制**：平移不变性通常通过局部感受野实现，这可能限制模型捕捉长距离依赖或大尺度结构的能力。\n",
    "\n",
    "&emsp;&emsp;参考：[https://arxiv.org/pdf/1805.12177.pdf](https://arxiv.org/pdf/1805.12177.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd187a-446b-4d90-87d0-754dc0457b3b",
   "metadata": {},
   "source": [
    "### 练习三\n",
    "\n",
    "3. 当从图像边界像素获取隐藏表示时，我们需要思考哪些问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d452d-a4f0-4198-8d60-de01dea5a71c",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456cb9b-a1c2-4db0-b5af-e9f3e074dd4b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从图像边界像素获取隐藏表示时，需要考虑一些特定的问题和挑战：\\\n",
    "&emsp;&emsp;1. **边界效应**：在图像边界处，像素的上下文信息可能不完整，这可能导致在提取特征时出现边界效应。边界像素没有足够的邻近像素来形成完整的局部模式，这可能影响隐藏表示的质量。\\\n",
    "&emsp;&emsp;2. **信息丢失**：边界像素通常不如图像中心区域的像素具有丰富的信息。在处理边界像素时，可能会丢失对整体图像理解至关重要的上下文信息。\\\n",
    "&emsp;&emsp;3. **尺度和旋转问题**：在边界区域，图像的尺度和旋转变化可能对隐藏表示产生更大的影响，尤其是在处理尺寸不一或旋转图像时。\\\n",
    "&emsp;&emsp;4. **填充策略的选择**：在使用卷积神经网络等工具时，可能需要对边界进行填充（如零填充）以保持特征图的尺寸。不同的填充策略可能会对边界像素的隐藏表示产生不同的影响。\\\n",
    "&emsp;&emsp;5. **噪声和伪影**：边界区域可能更容易受到图像处理过程中引入的噪声和伪影的影响，这可能会干扰隐藏表示的准确性。\\\n",
    "&emsp;&emsp;6. **特定应用的需求**：根据应用的不同，边界像素的处理方式可能需要调整。例如，在某些任务中，边界信息可能尤为重要，而在其他任务中，则可能不那么重要。\\\n",
    "&emsp;&emsp;为了有效地从图像边界像素获取隐藏表示，可能需要采用特殊的技术和策略，如使用特殊的卷积核、采用适应性边界处理方法或通过数据增强来模拟边界效应。此外，了解和评估边界像素对最终任务的影响也是很重要的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41bc29-587a-4b53-bd7a-8d32c54e8fd4",
   "metadata": {},
   "source": [
    "### 练习四\n",
    "\n",
    "4. 描述一个类似的音频卷积层的架构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f0386-1e62-449a-b883-c9e42a14e33b",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0da353-27d7-4467-8da6-d1693dcd30ed",
   "metadata": {},
   "source": [
    "&emsp;&emsp;一种基于卷积神经网络的音频特征生成方法，首先对声音信号进行预处理和离散傅里叶变换计算声音信号的幅度谱，形成二维谱图信号；然后搭建以上述二维谱图信号为输入的一维卷积神经网络并进行模型训练，得到特征生成器模型；最后对待测声音进行预处理和离散傅里叶变换得到二维谱图信号，并将其送入训练好的一维卷积神经网络，通过卷积网络计算，得到输出即为所要生成的音频特征，实现声音信号的音频特征生成。\n",
    "\n",
    "&emsp;&emsp;参考：https://blog.csdn.net/david_tym/article/details/112756785"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842fdaba-4482-49f9-8998-46b9ee22c495",
   "metadata": {},
   "source": [
    "### 练习五\n",
    "\n",
    "5. 卷积层也适合于文本数据吗？为什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab176ec-9ee2-4cb2-8512-414216a3405a",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8108d-203e-4675-a8ab-95f3fef52653",
   "metadata": {},
   "source": [
    "&emsp;&emsp;卷积层也适合于文本数据。\\\n",
    "&emsp;&emsp;在自然语言处理中，文本数据通常表示为词向量矩阵，其中每行代表一个词的向量表示。卷积层可以在这个矩阵上进行卷积操作，类似于图像卷积层中对图像进行卷积操作。 在卷积层中，卷积核会在输入矩阵上进行滑动窗口计算，输出一个新的特征矩阵。在文本数据中，这个特征矩阵可以看作是对输入文本的不同`n-gram`特征的提取。例如，一个大小为 $3$ 的卷积核可以提取出输入文本中每个长度为 $3$ 的`n-gram`特征。这些特征可以用于后续的分类或者回归任务。 此外，卷积层还可以与循环神经网络（`RNN`）结合使用，形成卷积神经网络（`CNN`）和循环神经网络（`RNN`）的混合模型。这种模型可以同时捕捉文本中的局部特征和全局特征，提高模型的性能。 因此，卷积层适用于文本数据，可以对文本数据进行卷积操作，提取出不同`n-gram`特征，并且可以与`RNN`结合使用，提高模型的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f8b42-a540-4b62-9a4a-8b9a0fb7d5a1",
   "metadata": {},
   "source": [
    "### 练习六\n",
    "\n",
    "6. 证明在 :eqref:`eq_2d-conv-discrete`中，$f * g = g * f$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5842219e-fed7-435c-81d8-19be0273feca",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee2185-a2d0-45cd-af74-60523fea65c2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;通过式(:eqref:eq_2d-conv-discrete)的定义，我们可以得到：\n",
    "\n",
    "$$(f * g)(x) = \\int_{-\\infty}^{\\infty}f(y)g(x-y)dy$$\n",
    "\n",
    "$$(g * f)(x) = \\int_{-\\infty}^{\\infty}g(y)f(x-y)dy$$\n",
    "\n",
    "&emsp;&emsp;要证明$f * g = g * f$，即证明：\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty}f(y)g(x-y)dy = \\int_{-\\infty}^{\\infty}g(y)f(x-y)dy$$\n",
    "\n",
    "&emsp;&emsp;为了证明上式成立，我们将其中一个积分的变量名改为$t=x-y$，则有：\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty}f(y)g(x-y)dy = \\int_{-\\infty}^{\\infty}f(x-t)g(t)dt$$\n",
    "\n",
    "&emsp;&emsp;[上式的推导过程](https://kimi.moonshot.cn/share/crbktlsubms7mvohjo0g)\n",
    "\n",
    "&emsp;&emsp;再将这个式子代回式(:eqref:eq_2d-conv-discrete)中：\n",
    "\n",
    "$$(f * g)(x) = \\int_{-\\infty}^{\\infty}f(x-t)g(t)dt$$\n",
    "\n",
    "&emsp;&emsp;对比式(:eqref:eq_2d-conv-discrete)和上面的式子，可以发现它们的形式是完全一样的，只是积分变量名不同而已。因此，我们可以得到：\n",
    "\n",
    "$$(f * g)(x) = \\int_{-\\infty}^{\\infty}f(y)g(x-y)dy = \\int_{-\\infty}^{\\infty}g(y)f(x-y)dy = (g * f)(x)$$\n",
    "\n",
    "&emsp;&emsp;因此，$f * g = g * f$，证毕。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
